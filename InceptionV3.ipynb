{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06368809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_files\n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, AveragePooling2D, Flatten, Dense, Dropout, Input\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "from keras.models import Model\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from PIL import ImageFile   \n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7f50a",
   "metadata": {
    "id": "H9G_XH6kpUzK"
   },
   "source": [
    "# Defining the train,test and model directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d594cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DIR = 'imgs/test'\n",
    "TRAIN_DIR = 'imgs/train'\n",
    "MODEL_PATH = 'model/GoogLeNet'\n",
    "PICKLE_PATH = 'pickle'\n",
    "CSV_DIR = 'csv_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb33db22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_DIR):\n",
    "    print(\"Testing data does not exists\")\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    print(\"Training data does not exists\")\n",
    "if not os.path.exists(MODEL_PATH):\n",
    "    print(\"Model ResNet path does not exists\")\n",
    "    os.makedirs(MODEL_PATH)\n",
    "    print(\"Model ResNet path created\")\n",
    "if not os.path.exists(PICKLE_PATH):\n",
    "    os.makedirs(PICKLE_DIR)\n",
    "if not os.path.exists(CSV_DIR):\n",
    "    os.makedirs(CSV_DIR)# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532b4b3c",
   "metadata": {
    "id": "DqulRns6DdX-"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32240579",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('csv_files/train.csv')\n",
    "data_test = pd.read_csv('csv_files/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7eea773",
   "metadata": {
    "id": "LPVE8wkaGdMY"
   },
   "source": [
    "### Converting into numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20403946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'c0': 0, 'c2': 1, 'c8': 2, 'c5': 3, 'c9': 4, 'c1': 5, 'c6': 6, 'c7': 7, 'c3': 8, 'c4': 9}\n"
     ]
    }
   ],
   "source": [
    "labels_list = list(set(data_train['ClassName'].values.tolist()))\n",
    "labels_id = {label_name:id for id,label_name in enumerate(labels_list)}\n",
    "print(labels_id)\n",
    "data_train['ClassName'].replace(labels_id,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9168a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle/labels_list.pkl', \"wb\") as handle:\n",
    "    pickle.dump(labels_id,handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "082047c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22424, 10)\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(data_train['ClassName'])\n",
    "print(labels.shape)# Splitting into Train and Test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba046815",
   "metadata": {
    "id": "srkiEMkdIAHY"
   },
   "source": [
    "# Splitting into Train and Test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bee2898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(data_train.iloc[:,0],labels,test_size = 0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "706ac318",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(128, 128))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (128, 128, 3)\n",
    "    x = image.img_to_array(img)\n",
    "   # convert 3D tensor to 4D tensor with shape (1, 128, 128, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3dd1f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 17939/17939 [01:11<00:00, 251.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 4485/4485 [00:16<00:00, 264.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(xtrain).astype('float32')/255 - 0.5\n",
    "valid_tensors = paths_to_tensor(xtest).astype('float32')/255 - 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15ff469",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35d98af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 63, 63, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 63, 63, 32)   96          conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 63, 63, 32)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 61, 61, 32)   9216        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 61, 61, 32)   96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 61, 61, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 61, 61, 64)   18432       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 61, 61, 64)   192         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 61, 61, 64)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 30, 30, 64)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 30, 30, 80)   5120        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 30, 30, 80)   240         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 30, 30, 80)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 28, 28, 192)  138240      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 28, 28, 192)  576         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 28, 28, 192)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 13, 13, 192)  0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 13, 13, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 13, 13, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 13, 13, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 13, 13, 48)   9216        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 13, 13, 96)   55296       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 13, 13, 48)   144         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 13, 13, 96)   288         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 13, 13, 48)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 13, 13, 96)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 13, 13, 192)  0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 13, 13, 64)   12288       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 13, 13, 64)   76800       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 13, 13, 96)   82944       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 13, 13, 32)   6144        average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 13, 13, 64)   192         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 13, 13, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 13, 13, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 13, 13, 32)   96          conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 13, 13, 64)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 13, 13, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 13, 13, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 13, 13, 32)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 13, 13, 256)  0           activation_5[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "                                                                 activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 13, 13, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 13, 13, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 13, 13, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 13, 13, 96)   55296       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 13, 13, 48)   144         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 13, 13, 96)   288         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 13, 13, 48)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 13, 13, 96)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 13, 13, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 13, 13, 64)   76800       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 13, 13, 96)   82944       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 13, 13, 64)   16384       average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 13, 13, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 13, 13, 64)   192         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 13, 13, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 13, 13, 64)   192         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 13, 13, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 13, 13, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 13, 13, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 13, 13, 64)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 13, 13, 288)  0           activation_12[0][0]              \n",
      "                                                                 activation_14[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 13, 13, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 13, 13, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 13, 13, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 13, 13, 96)   55296       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 13, 13, 48)   144         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 13, 13, 96)   288         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 13, 13, 48)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 13, 13, 96)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 13, 13, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 13, 13, 64)   76800       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 13, 13, 96)   82944       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 13, 13, 64)   18432       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 13, 13, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 13, 13, 64)   192         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 13, 13, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 13, 13, 64)   192         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 13, 13, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 13, 13, 64)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 13, 13, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 13, 13, 64)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 13, 13, 288)  0           activation_19[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "                                                                 activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 13, 13, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 13, 13, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 13, 13, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 13, 13, 96)   55296       activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 13, 13, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 13, 13, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 6, 6, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 6, 6, 96)     82944       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 6, 6, 384)    1152        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 6, 6, 96)     288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 6, 6, 384)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 6, 6, 96)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 6, 6, 768)    0           activation_26[0][0]              \n",
      "                                                                 activation_29[0][0]              \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 6, 6, 128)    384         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 6, 6, 128)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 6, 6, 128)    114688      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 6, 6, 128)    384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 6, 6, 128)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 6, 6, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 6, 6, 128)    384         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 6, 6, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 6, 6, 128)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 6, 6, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 6, 6, 128)    114688      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 6, 6, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 6, 6, 128)    384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 6, 6, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 6, 6, 128)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 6, 6, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 6, 6, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 6, 6, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 6, 6, 192)    172032      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 6, 6, 192)    172032      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 6, 6, 192)    576         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 6, 6, 192)    576         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 6, 6, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 6, 6, 192)    576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 6, 6, 192)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 6, 6, 192)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 6, 6, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 6, 6, 192)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 6, 6, 768)    0           activation_30[0][0]              \n",
      "                                                                 activation_33[0][0]              \n",
      "                                                                 activation_38[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 6, 6, 160)    480         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 6, 6, 160)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 6, 6, 160)    179200      activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 6, 6, 160)    480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 6, 6, 160)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 6, 6, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 6, 6, 160)    480         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 6, 6, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 6, 6, 160)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 6, 6, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 6, 6, 160)    179200      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 6, 6, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 6, 6, 160)    480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 6, 6, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 6, 6, 160)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 6, 6, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 6, 6, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 6, 6, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 6, 6, 192)    215040      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 6, 6, 192)    215040      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 6, 6, 192)    576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 6, 6, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 6, 6, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 6, 6, 192)    576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 6, 6, 192)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 6, 6, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 6, 6, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 6, 6, 192)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 6, 6, 768)    0           activation_40[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "                                                                 activation_48[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 6, 6, 160)    480         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 6, 6, 160)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 6, 6, 160)    179200      activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 6, 6, 160)    480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 6, 6, 160)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 6, 6, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 6, 6, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 6, 6, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 6, 6, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 6, 6, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 6, 6, 160)    179200      activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 6, 6, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 6, 6, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 6, 6, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 6, 6, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 6, 6, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 6, 6, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 6, 6, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 6, 6, 192)    215040      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 6, 6, 192)    215040      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 6, 6, 192)    576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 6, 6, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 6, 6, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 6, 6, 192)    576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 6, 6, 192)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 6, 6, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 6, 6, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 6, 6, 192)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 6, 6, 768)    0           activation_50[0][0]              \n",
      "                                                                 activation_53[0][0]              \n",
      "                                                                 activation_58[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 6, 6, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 6, 6, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 6, 6, 192)    258048      activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 6, 6, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 6, 6, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 6, 6, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 6, 6, 192)    576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 6, 6, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 6, 6, 192)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 6, 6, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 6, 6, 192)    258048      activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 6, 6, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 6, 6, 192)    576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 6, 6, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 6, 6, 192)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 6, 6, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 6, 6, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 6, 6, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 6, 6, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 6, 6, 192)    576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 6, 6, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 6, 6, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 6, 6, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 6, 6, 192)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 6, 6, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 6, 6, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 6, 6, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 6, 6, 768)    0           activation_60[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "                                                                 activation_68[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 6, 6, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 6, 6, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 6, 6, 192)    258048      activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 6, 6, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 6, 6, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 6, 6, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 6, 6, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 6, 6, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 6, 6, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 6, 6, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 2, 2, 320)    552960      activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 2, 2, 192)    331776      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 2, 2, 320)    960         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 2, 2, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 2, 2, 320)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 2, 2, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 2, 2, 1280)   0           activation_71[0][0]              \n",
      "                                                                 activation_75[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 2, 2, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 2, 2, 448)    1344        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 2, 2, 448)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 2, 2, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 2, 2, 384)    1548288     activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 2, 2, 384)    1152        conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 2, 2, 384)    1152        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 2, 2, 384)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 2, 2, 384)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 2, 2, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 2, 2, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 2, 2, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 2, 2, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 2, 2, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 2, 2, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 2, 2, 192)    245760      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 2, 2, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 2, 2, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 2, 2, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 2, 2, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 2, 2, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 2, 2, 192)    576         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 2, 2, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 2, 2, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 2, 2, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 2, 2, 192)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 2, 2, 2048)   0           activation_76[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 2, 2, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 2, 2, 448)    1344        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 2, 2, 448)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 2, 2, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 2, 2, 384)    1548288     activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 2, 2, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 2, 2, 384)    1152        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 2, 2, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 2, 2, 384)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 2, 2, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 2, 2, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 2, 2, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 2, 2, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 2, 2, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 2, 2, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 2, 2, 192)    393216      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 2, 2, 320)    960         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 2, 2, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 2, 2, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 2, 2, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 2, 2, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 2, 2, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 2, 2, 320)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 2, 2, 768)    0           activation_87[0][0]              \n",
      "                                                                 activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 768)    0           activation_91[0][0]              \n",
      "                                                                 activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 2, 2, 192)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 2, 2, 2048)   0           activation_85[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = InceptionV3(include_top=False, input_shape=(128,128,3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d087e436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "561/561 [==============================] - 33s 30ms/step\n",
      "141/141 [==============================] - 5s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "train_inception = model.predict(train_tensors,verbose=1)\n",
    "valid_inception = model.predict(valid_tensors,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6320a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape (17939, 2, 2, 2048)\n",
      "Validation shape (4485, 2, 2, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape\",train_inception.shape)\n",
    "print(\"Validation shape\",valid_inception.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07da5609",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_inception[0]\n",
    "valid_features = valid_inception[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f425aaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train features shape (2, 2, 2048)\n",
      "Validation features shape (2, 2, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train features shape\",train_features.shape)\n",
    "print(\"Validation features shape\",valid_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a56b568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 20,490\n",
      "Trainable params: 20,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "InceptionV3_model = Sequential()\n",
    "InceptionV3_model.add(GlobalAveragePooling2D(input_shape=train_features.shape))\n",
    "InceptionV3_model.add(Dense(10, activation='softmax', kernel_initializer='glorot_normal'))\n",
    "\n",
    "InceptionV3_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe03b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "InceptionV3_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "573940c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "filepath = os.path.join(MODEL_PATH,\"distracted-{epoch:02d}-{val_accuracy:.2f}.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max',period=1)\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06952ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1122/1122 [==============================] - 9s 3ms/step - loss: 1.8194 - accuracy: 0.4589 - val_loss: 0.7241 - val_accuracy: 0.7779\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.77793, saving model to model/GoogLeNet\\distracted-01-0.78.hdf5\n",
      "Epoch 2/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.6374 - accuracy: 0.7961 - val_loss: 0.8467 - val_accuracy: 0.7496\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.77793\n",
      "Epoch 3/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.4707 - accuracy: 0.8509 - val_loss: 0.4972 - val_accuracy: 0.8466\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.77793 to 0.84660, saving model to model/GoogLeNet\\distracted-03-0.85.hdf5\n",
      "Epoch 4/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3632 - accuracy: 0.8831 - val_loss: 0.4333 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.84660 to 0.87068, saving model to model/GoogLeNet\\distracted-04-0.87.hdf5\n",
      "Epoch 5/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.3058 - accuracy: 0.9040 - val_loss: 0.5411 - val_accuracy: 0.8459\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.87068\n",
      "Epoch 6/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2662 - accuracy: 0.9158 - val_loss: 0.4150 - val_accuracy: 0.8832\n",
      "\n",
      "Epoch 00006: val_accuracy improved from 0.87068 to 0.88317, saving model to model/GoogLeNet\\distracted-06-0.88.hdf5\n",
      "Epoch 7/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2397 - accuracy: 0.9233 - val_loss: 0.4119 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.88317\n",
      "Epoch 8/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.2238 - accuracy: 0.9289 - val_loss: 0.4589 - val_accuracy: 0.8713\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.88317\n",
      "Epoch 9/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1987 - accuracy: 0.9377 - val_loss: 0.5583 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.88317\n",
      "Epoch 10/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1888 - accuracy: 0.9395 - val_loss: 0.5335 - val_accuracy: 0.8627\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.88317\n",
      "Epoch 11/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1603 - accuracy: 0.9478 - val_loss: 0.4301 - val_accuracy: 0.8825\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.88317\n",
      "Epoch 12/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1499 - accuracy: 0.9523 - val_loss: 0.4983 - val_accuracy: 0.8689\n",
      "\n",
      "Epoch 00012: val_accuracy did not improve from 0.88317\n",
      "Epoch 13/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1445 - accuracy: 0.9530 - val_loss: 0.6544 - val_accuracy: 0.8435\n",
      "\n",
      "Epoch 00013: val_accuracy did not improve from 0.88317\n",
      "Epoch 14/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.1289 - accuracy: 0.9572 - val_loss: 0.4872 - val_accuracy: 0.8825\n",
      "\n",
      "Epoch 00014: val_accuracy did not improve from 0.88317\n",
      "Epoch 15/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1215 - accuracy: 0.9597 - val_loss: 0.5229 - val_accuracy: 0.8676\n",
      "\n",
      "Epoch 00015: val_accuracy did not improve from 0.88317\n",
      "Epoch 16/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.1195 - accuracy: 0.9610 - val_loss: 0.4557 - val_accuracy: 0.8843\n",
      "\n",
      "Epoch 00016: val_accuracy improved from 0.88317 to 0.88428, saving model to model/GoogLeNet\\distracted-16-0.88.hdf5\n",
      "Epoch 17/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.1092 - accuracy: 0.9634 - val_loss: 0.4453 - val_accuracy: 0.8896\n",
      "\n",
      "Epoch 00017: val_accuracy improved from 0.88428 to 0.88963, saving model to model/GoogLeNet\\distracted-17-0.89.hdf5\n",
      "Epoch 18/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.1005 - accuracy: 0.9668 - val_loss: 0.4231 - val_accuracy: 0.9012\n",
      "\n",
      "Epoch 00018: val_accuracy improved from 0.88963 to 0.90123, saving model to model/GoogLeNet\\distracted-18-0.90.hdf5\n",
      "Epoch 19/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0976 - accuracy: 0.9668 - val_loss: 0.5055 - val_accuracy: 0.8870\n",
      "\n",
      "Epoch 00019: val_accuracy did not improve from 0.90123\n",
      "Epoch 20/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0930 - accuracy: 0.9686 - val_loss: 0.4524 - val_accuracy: 0.8954\n",
      "\n",
      "Epoch 00020: val_accuracy did not improve from 0.90123\n",
      "Epoch 21/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0937 - accuracy: 0.9707 - val_loss: 0.6473 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00021: val_accuracy did not improve from 0.90123\n",
      "Epoch 22/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0877 - accuracy: 0.9698 - val_loss: 0.4489 - val_accuracy: 0.8948\n",
      "\n",
      "Epoch 00022: val_accuracy did not improve from 0.90123\n",
      "Epoch 23/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0826 - accuracy: 0.9734 - val_loss: 0.4631 - val_accuracy: 0.8968\n",
      "\n",
      "Epoch 00023: val_accuracy did not improve from 0.90123\n",
      "Epoch 24/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0698 - accuracy: 0.9774 - val_loss: 0.4490 - val_accuracy: 0.8952\n",
      "\n",
      "Epoch 00024: val_accuracy did not improve from 0.90123\n",
      "Epoch 25/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0707 - accuracy: 0.9774 - val_loss: 0.4365 - val_accuracy: 0.9059\n",
      "\n",
      "Epoch 00025: val_accuracy improved from 0.90123 to 0.90591, saving model to model/GoogLeNet\\distracted-25-0.91.hdf5\n",
      "Epoch 26/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0690 - accuracy: 0.9788 - val_loss: 0.4455 - val_accuracy: 0.9046\n",
      "\n",
      "Epoch 00026: val_accuracy did not improve from 0.90591\n",
      "Epoch 27/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0648 - accuracy: 0.9788 - val_loss: 0.4560 - val_accuracy: 0.9048\n",
      "\n",
      "Epoch 00027: val_accuracy did not improve from 0.90591\n",
      "Epoch 28/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0608 - accuracy: 0.9797 - val_loss: 0.5031 - val_accuracy: 0.8970\n",
      "\n",
      "Epoch 00028: val_accuracy did not improve from 0.90591\n",
      "Epoch 29/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0572 - accuracy: 0.9811 - val_loss: 0.5464 - val_accuracy: 0.8834\n",
      "\n",
      "Epoch 00029: val_accuracy did not improve from 0.90591\n",
      "Epoch 30/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0594 - accuracy: 0.9801 - val_loss: 0.6249 - val_accuracy: 0.8745\n",
      "\n",
      "Epoch 00030: val_accuracy did not improve from 0.90591\n",
      "Epoch 31/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0526 - accuracy: 0.9830 - val_loss: 0.4859 - val_accuracy: 0.9010\n",
      "\n",
      "Epoch 00031: val_accuracy did not improve from 0.90591\n",
      "Epoch 32/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0496 - accuracy: 0.9841 - val_loss: 0.6057 - val_accuracy: 0.8856\n",
      "\n",
      "Epoch 00032: val_accuracy did not improve from 0.90591\n",
      "Epoch 33/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0492 - accuracy: 0.9842 - val_loss: 0.5524 - val_accuracy: 0.8896\n",
      "\n",
      "Epoch 00033: val_accuracy did not improve from 0.90591\n",
      "Epoch 34/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0485 - accuracy: 0.9847 - val_loss: 0.5444 - val_accuracy: 0.8912\n",
      "\n",
      "Epoch 00034: val_accuracy did not improve from 0.90591\n",
      "Epoch 35/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0452 - accuracy: 0.9859 - val_loss: 0.5420 - val_accuracy: 0.8963\n",
      "\n",
      "Epoch 00035: val_accuracy did not improve from 0.90591\n",
      "Epoch 36/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0417 - accuracy: 0.9862 - val_loss: 0.5455 - val_accuracy: 0.8945\n",
      "\n",
      "Epoch 00036: val_accuracy did not improve from 0.90591\n",
      "Epoch 37/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0446 - accuracy: 0.9863 - val_loss: 0.5529 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00037: val_accuracy did not improve from 0.90591\n",
      "Epoch 38/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0399 - accuracy: 0.9879 - val_loss: 0.5524 - val_accuracy: 0.8928\n",
      "\n",
      "Epoch 00038: val_accuracy did not improve from 0.90591\n",
      "Epoch 39/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0410 - accuracy: 0.9878 - val_loss: 0.5501 - val_accuracy: 0.8945\n",
      "\n",
      "Epoch 00039: val_accuracy did not improve from 0.90591\n",
      "Epoch 40/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0355 - accuracy: 0.9874 - val_loss: 0.5693 - val_accuracy: 0.8919\n",
      "\n",
      "Epoch 00040: val_accuracy did not improve from 0.90591\n",
      "Epoch 41/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0344 - accuracy: 0.9886 - val_loss: 0.6913 - val_accuracy: 0.8687\n",
      "\n",
      "Epoch 00041: val_accuracy did not improve from 0.90591\n",
      "Epoch 42/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0344 - accuracy: 0.9883 - val_loss: 0.6058 - val_accuracy: 0.8883\n",
      "\n",
      "Epoch 00042: val_accuracy did not improve from 0.90591\n",
      "Epoch 43/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0349 - accuracy: 0.9893 - val_loss: 0.5600 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00043: val_accuracy did not improve from 0.90591\n",
      "Epoch 44/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0346 - accuracy: 0.9894 - val_loss: 0.6029 - val_accuracy: 0.8945\n",
      "\n",
      "Epoch 00044: val_accuracy did not improve from 0.90591\n",
      "Epoch 45/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0317 - accuracy: 0.9906 - val_loss: 0.6197 - val_accuracy: 0.8903\n",
      "\n",
      "Epoch 00045: val_accuracy did not improve from 0.90591\n",
      "Epoch 46/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0306 - accuracy: 0.9905 - val_loss: 0.6094 - val_accuracy: 0.8934\n",
      "\n",
      "Epoch 00046: val_accuracy did not improve from 0.90591\n",
      "Epoch 47/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0309 - accuracy: 0.9902 - val_loss: 0.6217 - val_accuracy: 0.8921\n",
      "\n",
      "Epoch 00047: val_accuracy did not improve from 0.90591\n",
      "Epoch 48/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0267 - accuracy: 0.9912 - val_loss: 0.6411 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00048: val_accuracy did not improve from 0.90591\n",
      "Epoch 49/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0261 - accuracy: 0.9929 - val_loss: 0.6012 - val_accuracy: 0.8952\n",
      "\n",
      "Epoch 00049: val_accuracy did not improve from 0.90591\n",
      "Epoch 50/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0259 - accuracy: 0.9925 - val_loss: 0.6787 - val_accuracy: 0.8827\n",
      "\n",
      "Epoch 00050: val_accuracy did not improve from 0.90591\n",
      "Epoch 51/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0269 - accuracy: 0.9917 - val_loss: 0.6199 - val_accuracy: 0.8921\n",
      "\n",
      "Epoch 00051: val_accuracy did not improve from 0.90591\n",
      "Epoch 52/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0262 - accuracy: 0.9926 - val_loss: 0.6267 - val_accuracy: 0.8974\n",
      "\n",
      "Epoch 00052: val_accuracy did not improve from 0.90591\n",
      "Epoch 53/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0225 - accuracy: 0.9924 - val_loss: 0.6964 - val_accuracy: 0.8816\n",
      "\n",
      "Epoch 00053: val_accuracy did not improve from 0.90591\n",
      "Epoch 54/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0241 - accuracy: 0.9927 - val_loss: 0.6458 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00054: val_accuracy did not improve from 0.90591\n",
      "Epoch 55/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0222 - accuracy: 0.9932 - val_loss: 0.7093 - val_accuracy: 0.8856\n",
      "\n",
      "Epoch 00055: val_accuracy did not improve from 0.90591\n",
      "Epoch 56/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0235 - accuracy: 0.9914 - val_loss: 0.6663 - val_accuracy: 0.8923\n",
      "\n",
      "Epoch 00056: val_accuracy did not improve from 0.90591\n",
      "Epoch 57/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0217 - accuracy: 0.9930 - val_loss: 0.6621 - val_accuracy: 0.8919\n",
      "\n",
      "Epoch 00057: val_accuracy did not improve from 0.90591\n",
      "Epoch 58/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0180 - accuracy: 0.9945 - val_loss: 0.6709 - val_accuracy: 0.8925\n",
      "\n",
      "Epoch 00058: val_accuracy did not improve from 0.90591\n",
      "Epoch 59/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0203 - accuracy: 0.9937 - val_loss: 0.7294 - val_accuracy: 0.8861\n",
      "\n",
      "Epoch 00059: val_accuracy did not improve from 0.90591\n",
      "Epoch 60/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0205 - accuracy: 0.9934 - val_loss: 0.7517 - val_accuracy: 0.8843\n",
      "\n",
      "Epoch 00060: val_accuracy did not improve from 0.90591\n",
      "Epoch 61/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0178 - accuracy: 0.9950 - val_loss: 0.7049 - val_accuracy: 0.8887\n",
      "\n",
      "Epoch 00061: val_accuracy did not improve from 0.90591\n",
      "Epoch 62/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0183 - accuracy: 0.9950 - val_loss: 0.6739 - val_accuracy: 0.8948\n",
      "\n",
      "Epoch 00062: val_accuracy did not improve from 0.90591\n",
      "Epoch 63/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.7582 - val_accuracy: 0.8827\n",
      "\n",
      "Epoch 00063: val_accuracy did not improve from 0.90591\n",
      "Epoch 64/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.7425 - val_accuracy: 0.8827\n",
      "\n",
      "Epoch 00064: val_accuracy did not improve from 0.90591\n",
      "Epoch 65/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0150 - accuracy: 0.9957 - val_loss: 0.7906 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00065: val_accuracy did not improve from 0.90591\n",
      "Epoch 66/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0149 - accuracy: 0.9955 - val_loss: 0.7398 - val_accuracy: 0.8910\n",
      "\n",
      "Epoch 00066: val_accuracy did not improve from 0.90591\n",
      "Epoch 67/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0155 - accuracy: 0.9947 - val_loss: 0.7709 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00067: val_accuracy did not improve from 0.90591\n",
      "Epoch 68/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0167 - accuracy: 0.9944 - val_loss: 0.7571 - val_accuracy: 0.8892\n",
      "\n",
      "Epoch 00068: val_accuracy did not improve from 0.90591\n",
      "Epoch 69/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0146 - accuracy: 0.9953 - val_loss: 0.7623 - val_accuracy: 0.8849\n",
      "\n",
      "Epoch 00069: val_accuracy did not improve from 0.90591\n",
      "Epoch 70/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.7510 - val_accuracy: 0.8901\n",
      "\n",
      "Epoch 00070: val_accuracy did not improve from 0.90591\n",
      "Epoch 71/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.7623 - val_accuracy: 0.8861\n",
      "\n",
      "Epoch 00071: val_accuracy did not improve from 0.90591\n",
      "Epoch 72/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0144 - accuracy: 0.9953 - val_loss: 0.7611 - val_accuracy: 0.8874\n",
      "\n",
      "Epoch 00072: val_accuracy did not improve from 0.90591\n",
      "Epoch 73/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0158 - accuracy: 0.9952 - val_loss: 0.8461 - val_accuracy: 0.8852\n",
      "\n",
      "Epoch 00073: val_accuracy did not improve from 0.90591\n",
      "Epoch 74/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0149 - accuracy: 0.9960 - val_loss: 0.8274 - val_accuracy: 0.8798\n",
      "\n",
      "Epoch 00074: val_accuracy did not improve from 0.90591\n",
      "Epoch 75/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0113 - accuracy: 0.9969 - val_loss: 0.8722 - val_accuracy: 0.8767\n",
      "\n",
      "Epoch 00075: val_accuracy did not improve from 0.90591\n",
      "Epoch 76/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.8104 - val_accuracy: 0.8849\n",
      "\n",
      "Epoch 00076: val_accuracy did not improve from 0.90591\n",
      "Epoch 77/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0117 - accuracy: 0.9968 - val_loss: 0.8144 - val_accuracy: 0.8856\n",
      "\n",
      "Epoch 00077: val_accuracy did not improve from 0.90591\n",
      "Epoch 78/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0108 - accuracy: 0.9968 - val_loss: 0.8305 - val_accuracy: 0.8878\n",
      "\n",
      "Epoch 00078: val_accuracy did not improve from 0.90591\n",
      "Epoch 79/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.8402 - val_accuracy: 0.8816\n",
      "\n",
      "Epoch 00079: val_accuracy did not improve from 0.90591\n",
      "Epoch 80/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0115 - accuracy: 0.9969 - val_loss: 0.8212 - val_accuracy: 0.8881\n",
      "\n",
      "Epoch 00080: val_accuracy did not improve from 0.90591\n",
      "Epoch 81/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0124 - accuracy: 0.9958 - val_loss: 0.8198 - val_accuracy: 0.8876\n",
      "\n",
      "Epoch 00081: val_accuracy did not improve from 0.90591\n",
      "Epoch 82/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.7956 - val_accuracy: 0.8936\n",
      "\n",
      "Epoch 00082: val_accuracy did not improve from 0.90591\n",
      "Epoch 83/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0093 - accuracy: 0.9974 - val_loss: 0.8546 - val_accuracy: 0.8892\n",
      "\n",
      "Epoch 00083: val_accuracy did not improve from 0.90591\n",
      "Epoch 84/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.8535 - val_accuracy: 0.8849\n",
      "\n",
      "Epoch 00084: val_accuracy did not improve from 0.90591\n",
      "Epoch 85/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0105 - accuracy: 0.9968 - val_loss: 0.8519 - val_accuracy: 0.8849\n",
      "\n",
      "Epoch 00085: val_accuracy did not improve from 0.90591\n",
      "Epoch 86/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0094 - accuracy: 0.9981 - val_loss: 0.8339 - val_accuracy: 0.8899\n",
      "\n",
      "Epoch 00086: val_accuracy did not improve from 0.90591\n",
      "Epoch 87/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.8340 - val_accuracy: 0.8894\n",
      "\n",
      "Epoch 00087: val_accuracy did not improve from 0.90591\n",
      "Epoch 88/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0090 - accuracy: 0.9977 - val_loss: 0.8551 - val_accuracy: 0.8892\n",
      "\n",
      "Epoch 00088: val_accuracy did not improve from 0.90591\n",
      "Epoch 89/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0088 - accuracy: 0.9973 - val_loss: 0.8519 - val_accuracy: 0.8892\n",
      "\n",
      "Epoch 00089: val_accuracy did not improve from 0.90591\n",
      "Epoch 90/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0100 - accuracy: 0.9974 - val_loss: 0.8682 - val_accuracy: 0.8907\n",
      "\n",
      "Epoch 00090: val_accuracy did not improve from 0.90591\n",
      "Epoch 91/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0102 - accuracy: 0.9974 - val_loss: 0.9390 - val_accuracy: 0.8832\n",
      "\n",
      "Epoch 00091: val_accuracy did not improve from 0.90591\n",
      "Epoch 92/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0067 - accuracy: 0.9984 - val_loss: 0.9104 - val_accuracy: 0.8841\n",
      "\n",
      "Epoch 00092: val_accuracy did not improve from 0.90591\n",
      "Epoch 93/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0093 - accuracy: 0.9976 - val_loss: 0.8738 - val_accuracy: 0.8881\n",
      "\n",
      "Epoch 00093: val_accuracy did not improve from 0.90591\n",
      "Epoch 94/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0082 - accuracy: 0.9979 - val_loss: 0.9351 - val_accuracy: 0.8847\n",
      "\n",
      "Epoch 00094: val_accuracy did not improve from 0.90591\n",
      "Epoch 95/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0081 - accuracy: 0.9984 - val_loss: 0.9115 - val_accuracy: 0.8881\n",
      "\n",
      "Epoch 00095: val_accuracy did not improve from 0.90591\n",
      "Epoch 96/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0078 - accuracy: 0.9980 - val_loss: 1.0402 - val_accuracy: 0.8678\n",
      "\n",
      "Epoch 00096: val_accuracy did not improve from 0.90591\n",
      "Epoch 97/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0086 - accuracy: 0.9981 - val_loss: 0.8913 - val_accuracy: 0.8890\n",
      "\n",
      "Epoch 00097: val_accuracy did not improve from 0.90591\n",
      "Epoch 98/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.9193 - val_accuracy: 0.8881\n",
      "\n",
      "Epoch 00098: val_accuracy did not improve from 0.90591\n",
      "Epoch 99/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0093 - accuracy: 0.9978 - val_loss: 0.9334 - val_accuracy: 0.8905\n",
      "\n",
      "Epoch 00099: val_accuracy did not improve from 0.90591\n",
      "Epoch 100/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.9657 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00100: val_accuracy did not improve from 0.90591\n",
      "Epoch 101/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0058 - accuracy: 0.9982 - val_loss: 0.9749 - val_accuracy: 0.8829\n",
      "\n",
      "Epoch 00101: val_accuracy did not improve from 0.90591\n",
      "Epoch 102/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0076 - accuracy: 0.9979 - val_loss: 0.9462 - val_accuracy: 0.8858\n",
      "\n",
      "Epoch 00102: val_accuracy did not improve from 0.90591\n",
      "Epoch 103/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0061 - accuracy: 0.9979 - val_loss: 0.9255 - val_accuracy: 0.8858\n",
      "\n",
      "Epoch 00103: val_accuracy did not improve from 0.90591\n",
      "Epoch 104/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.9405 - val_accuracy: 0.8858\n",
      "\n",
      "Epoch 00104: val_accuracy did not improve from 0.90591\n",
      "Epoch 105/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.9723 - val_accuracy: 0.8827\n",
      "\n",
      "Epoch 00105: val_accuracy did not improve from 0.90591\n",
      "Epoch 106/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.9978 - val_accuracy: 0.8832\n",
      "\n",
      "Epoch 00106: val_accuracy did not improve from 0.90591\n",
      "Epoch 107/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0073 - accuracy: 0.9981 - val_loss: 1.0601 - val_accuracy: 0.8776\n",
      "\n",
      "Epoch 00107: val_accuracy did not improve from 0.90591\n",
      "Epoch 108/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0083 - accuracy: 0.9981 - val_loss: 1.0765 - val_accuracy: 0.8780\n",
      "\n",
      "Epoch 00108: val_accuracy did not improve from 0.90591\n",
      "Epoch 109/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0114 - accuracy: 0.9963 - val_loss: 1.0232 - val_accuracy: 0.8796\n",
      "\n",
      "Epoch 00109: val_accuracy did not improve from 0.90591\n",
      "Epoch 110/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 1.0223 - val_accuracy: 0.8814\n",
      "\n",
      "Epoch 00110: val_accuracy did not improve from 0.90591\n",
      "Epoch 111/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0053 - accuracy: 0.9983 - val_loss: 0.9925 - val_accuracy: 0.8843\n",
      "\n",
      "Epoch 00111: val_accuracy did not improve from 0.90591\n",
      "Epoch 112/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 1.0392 - val_accuracy: 0.8792\n",
      "\n",
      "Epoch 00112: val_accuracy did not improve from 0.90591\n",
      "Epoch 113/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 1.0266 - val_accuracy: 0.8847\n",
      "\n",
      "Epoch 00113: val_accuracy did not improve from 0.90591\n",
      "Epoch 114/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 1.0604 - val_accuracy: 0.8829\n",
      "\n",
      "Epoch 00114: val_accuracy did not improve from 0.90591\n",
      "Epoch 115/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0066 - accuracy: 0.9982 - val_loss: 1.0350 - val_accuracy: 0.8870\n",
      "\n",
      "Epoch 00115: val_accuracy did not improve from 0.90591\n",
      "Epoch 116/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0062 - accuracy: 0.9986 - val_loss: 1.0643 - val_accuracy: 0.8812\n",
      "\n",
      "Epoch 00116: val_accuracy did not improve from 0.90591\n",
      "Epoch 117/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0065 - accuracy: 0.9983 - val_loss: 1.0319 - val_accuracy: 0.8823\n",
      "\n",
      "Epoch 00117: val_accuracy did not improve from 0.90591\n",
      "Epoch 118/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0048 - accuracy: 0.9981 - val_loss: 1.2137 - val_accuracy: 0.8671\n",
      "\n",
      "Epoch 00118: val_accuracy did not improve from 0.90591\n",
      "Epoch 119/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0063 - accuracy: 0.9986 - val_loss: 1.1226 - val_accuracy: 0.8783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00119: val_accuracy did not improve from 0.90591\n",
      "Epoch 120/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0063 - accuracy: 0.9984 - val_loss: 1.0572 - val_accuracy: 0.8845\n",
      "\n",
      "Epoch 00120: val_accuracy did not improve from 0.90591\n",
      "Epoch 121/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 1.0812 - val_accuracy: 0.8800\n",
      "\n",
      "Epoch 00121: val_accuracy did not improve from 0.90591\n",
      "Epoch 122/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 1.1457 - val_accuracy: 0.8760\n",
      "\n",
      "Epoch 00122: val_accuracy did not improve from 0.90591\n",
      "Epoch 123/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 1.0946 - val_accuracy: 0.8798\n",
      "\n",
      "Epoch 00123: val_accuracy did not improve from 0.90591\n",
      "Epoch 124/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 1.0966 - val_accuracy: 0.8825\n",
      "\n",
      "Epoch 00124: val_accuracy did not improve from 0.90591\n",
      "Epoch 125/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 1.1130 - val_accuracy: 0.8823\n",
      "\n",
      "Epoch 00125: val_accuracy did not improve from 0.90591\n",
      "Epoch 126/400\n",
      "1122/1122 [==============================] - 4s 4ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 1.1093 - val_accuracy: 0.8832\n",
      "\n",
      "Epoch 00126: val_accuracy did not improve from 0.90591\n",
      "Epoch 127/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 1.1047 - val_accuracy: 0.8847\n",
      "\n",
      "Epoch 00127: val_accuracy did not improve from 0.90591\n",
      "Epoch 128/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 1.2635 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00128: val_accuracy did not improve from 0.90591\n",
      "Epoch 129/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 1.2139 - val_accuracy: 0.8756\n",
      "\n",
      "Epoch 00129: val_accuracy did not improve from 0.90591\n",
      "Epoch 130/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0044 - accuracy: 0.9989 - val_loss: 1.1075 - val_accuracy: 0.8847\n",
      "\n",
      "Epoch 00130: val_accuracy did not improve from 0.90591\n",
      "Epoch 131/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0046 - accuracy: 0.9989 - val_loss: 1.1349 - val_accuracy: 0.8812\n",
      "\n",
      "Epoch 00131: val_accuracy did not improve from 0.90591\n",
      "Epoch 132/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 1.1479 - val_accuracy: 0.8827\n",
      "\n",
      "Epoch 00132: val_accuracy did not improve from 0.90591\n",
      "Epoch 133/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0043 - accuracy: 0.9990 - val_loss: 1.1903 - val_accuracy: 0.8765\n",
      "\n",
      "Epoch 00133: val_accuracy did not improve from 0.90591\n",
      "Epoch 134/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 1.1973 - val_accuracy: 0.8783\n",
      "\n",
      "Epoch 00134: val_accuracy did not improve from 0.90591\n",
      "Epoch 135/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 1.1447 - val_accuracy: 0.8798\n",
      "\n",
      "Epoch 00135: val_accuracy did not improve from 0.90591\n",
      "Epoch 136/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0047 - accuracy: 0.9986 - val_loss: 1.1756 - val_accuracy: 0.8805\n",
      "\n",
      "Epoch 00136: val_accuracy did not improve from 0.90591\n",
      "Epoch 137/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 1.2064 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00137: val_accuracy did not improve from 0.90591\n",
      "Epoch 138/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0043 - accuracy: 0.9987 - val_loss: 1.1664 - val_accuracy: 0.8794\n",
      "\n",
      "Epoch 00138: val_accuracy did not improve from 0.90591\n",
      "Epoch 139/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 1.2960 - val_accuracy: 0.8671\n",
      "\n",
      "Epoch 00139: val_accuracy did not improve from 0.90591\n",
      "Epoch 140/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 1.2317 - val_accuracy: 0.8718\n",
      "\n",
      "Epoch 00140: val_accuracy did not improve from 0.90591\n",
      "Epoch 141/400\n",
      "1122/1122 [==============================] - 4s 4ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 1.2936 - val_accuracy: 0.8742\n",
      "\n",
      "Epoch 00141: val_accuracy did not improve from 0.90591\n",
      "Epoch 142/400\n",
      "1122/1122 [==============================] - 4s 4ms/step - loss: 0.0043 - accuracy: 0.9984 - val_loss: 1.2105 - val_accuracy: 0.8796\n",
      "\n",
      "Epoch 00142: val_accuracy did not improve from 0.90591\n",
      "Epoch 143/400\n",
      "1122/1122 [==============================] - 4s 4ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 1.2236 - val_accuracy: 0.8792\n",
      "\n",
      "Epoch 00143: val_accuracy did not improve from 0.90591\n",
      "Epoch 144/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 1.2329 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00144: val_accuracy did not improve from 0.90591\n",
      "Epoch 145/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0027 - accuracy: 0.9996 - val_loss: 1.2482 - val_accuracy: 0.8809\n",
      "\n",
      "Epoch 00145: val_accuracy did not improve from 0.90591\n",
      "Epoch 146/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 1.2334 - val_accuracy: 0.8792\n",
      "\n",
      "Epoch 00146: val_accuracy did not improve from 0.90591\n",
      "Epoch 147/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 1.2597 - val_accuracy: 0.8789\n",
      "\n",
      "Epoch 00147: val_accuracy did not improve from 0.90591\n",
      "Epoch 148/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 1.2240 - val_accuracy: 0.8796\n",
      "\n",
      "Epoch 00148: val_accuracy did not improve from 0.90591\n",
      "Epoch 149/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 1.2527 - val_accuracy: 0.8745\n",
      "\n",
      "Epoch 00149: val_accuracy did not improve from 0.90591\n",
      "Epoch 150/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 1.2929 - val_accuracy: 0.8767\n",
      "\n",
      "Epoch 00150: val_accuracy did not improve from 0.90591\n",
      "Epoch 151/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9991 - val_loss: 1.2587 - val_accuracy: 0.8760\n",
      "\n",
      "Epoch 00151: val_accuracy did not improve from 0.90591\n",
      "Epoch 152/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 1.2687 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00152: val_accuracy did not improve from 0.90591\n",
      "Epoch 153/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 1.3080 - val_accuracy: 0.8794\n",
      "\n",
      "Epoch 00153: val_accuracy did not improve from 0.90591\n",
      "Epoch 154/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 1.3360 - val_accuracy: 0.8720\n",
      "\n",
      "Epoch 00154: val_accuracy did not improve from 0.90591\n",
      "Epoch 155/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0034 - accuracy: 0.9987 - val_loss: 1.3265 - val_accuracy: 0.8783\n",
      "\n",
      "Epoch 00155: val_accuracy did not improve from 0.90591\n",
      "Epoch 156/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 1.3026 - val_accuracy: 0.8780\n",
      "\n",
      "Epoch 00156: val_accuracy did not improve from 0.90591\n",
      "Epoch 157/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0028 - accuracy: 0.9996 - val_loss: 1.3134 - val_accuracy: 0.8740\n",
      "\n",
      "Epoch 00157: val_accuracy did not improve from 0.90591\n",
      "Epoch 158/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0024 - accuracy: 0.9993 - val_loss: 1.3757 - val_accuracy: 0.8727\n",
      "\n",
      "Epoch 00158: val_accuracy did not improve from 0.90591\n",
      "Epoch 159/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 1.3458 - val_accuracy: 0.8763\n",
      "\n",
      "Epoch 00159: val_accuracy did not improve from 0.90591\n",
      "Epoch 160/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 1.3339 - val_accuracy: 0.8765\n",
      "\n",
      "Epoch 00160: val_accuracy did not improve from 0.90591\n",
      "Epoch 161/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 1.3310 - val_accuracy: 0.8756\n",
      "\n",
      "Epoch 00161: val_accuracy did not improve from 0.90591\n",
      "Epoch 162/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 1.3320 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00162: val_accuracy did not improve from 0.90591\n",
      "Epoch 163/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 1.3552 - val_accuracy: 0.8742\n",
      "\n",
      "Epoch 00163: val_accuracy did not improve from 0.90591\n",
      "Epoch 164/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 1.4105 - val_accuracy: 0.8745\n",
      "\n",
      "Epoch 00164: val_accuracy did not improve from 0.90591\n",
      "Epoch 165/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 1.3498 - val_accuracy: 0.8785\n",
      "\n",
      "Epoch 00165: val_accuracy did not improve from 0.90591\n",
      "Epoch 166/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 1.4129 - val_accuracy: 0.8738\n",
      "\n",
      "Epoch 00166: val_accuracy did not improve from 0.90591\n",
      "Epoch 167/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 1.3715 - val_accuracy: 0.8767\n",
      "\n",
      "Epoch 00167: val_accuracy did not improve from 0.90591\n",
      "Epoch 168/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0021 - accuracy: 0.9996 - val_loss: 1.4350 - val_accuracy: 0.8711\n",
      "\n",
      "Epoch 00168: val_accuracy did not improve from 0.90591\n",
      "Epoch 169/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 1.3866 - val_accuracy: 0.8776\n",
      "\n",
      "Epoch 00169: val_accuracy did not improve from 0.90591\n",
      "Epoch 170/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 1.4629 - val_accuracy: 0.8731\n",
      "\n",
      "Epoch 00170: val_accuracy did not improve from 0.90591\n",
      "Epoch 171/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 1.4461 - val_accuracy: 0.8756\n",
      "\n",
      "Epoch 00171: val_accuracy did not improve from 0.90591\n",
      "Epoch 172/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 1.4291 - val_accuracy: 0.8758\n",
      "\n",
      "Epoch 00172: val_accuracy did not improve from 0.90591\n",
      "Epoch 173/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 1.4466 - val_accuracy: 0.8725\n",
      "\n",
      "Epoch 00173: val_accuracy did not improve from 0.90591\n",
      "Epoch 174/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 1.5260 - val_accuracy: 0.8678\n",
      "\n",
      "Epoch 00174: val_accuracy did not improve from 0.90591\n",
      "Epoch 175/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0027 - accuracy: 0.9989 - val_loss: 1.4341 - val_accuracy: 0.8745\n",
      "\n",
      "Epoch 00175: val_accuracy did not improve from 0.90591\n",
      "Epoch 176/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 1.4478 - val_accuracy: 0.8774\n",
      "\n",
      "Epoch 00176: val_accuracy did not improve from 0.90591\n",
      "Epoch 177/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 1.4553 - val_accuracy: 0.8765\n",
      "\n",
      "Epoch 00177: val_accuracy did not improve from 0.90591\n",
      "Epoch 178/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 1.4555 - val_accuracy: 0.8747\n",
      "\n",
      "Epoch 00178: val_accuracy did not improve from 0.90591\n",
      "Epoch 179/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 1.4738 - val_accuracy: 0.8702\n",
      "\n",
      "Epoch 00179: val_accuracy did not improve from 0.90591\n",
      "Epoch 180/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 1.4726 - val_accuracy: 0.8736\n",
      "\n",
      "Epoch 00180: val_accuracy did not improve from 0.90591\n",
      "Epoch 181/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 1.4563 - val_accuracy: 0.8758\n",
      "\n",
      "Epoch 00181: val_accuracy did not improve from 0.90591\n",
      "Epoch 182/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 1.5555 - val_accuracy: 0.8693\n",
      "\n",
      "Epoch 00182: val_accuracy did not improve from 0.90591\n",
      "Epoch 183/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 1.4651 - val_accuracy: 0.8776\n",
      "\n",
      "Epoch 00183: val_accuracy did not improve from 0.90591\n",
      "Epoch 184/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 1.4942 - val_accuracy: 0.8765\n",
      "\n",
      "Epoch 00184: val_accuracy did not improve from 0.90591\n",
      "Epoch 185/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 1.5169 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00185: val_accuracy did not improve from 0.90591\n",
      "Epoch 186/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 1.4987 - val_accuracy: 0.8769\n",
      "\n",
      "Epoch 00186: val_accuracy did not improve from 0.90591\n",
      "Epoch 187/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 0.9995 - val_loss: 1.5449 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00187: val_accuracy did not improve from 0.90591\n",
      "Epoch 188/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 1.5120 - val_accuracy: 0.8718\n",
      "\n",
      "Epoch 00188: val_accuracy did not improve from 0.90591\n",
      "Epoch 189/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 1.5458 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00189: val_accuracy did not improve from 0.90591\n",
      "Epoch 190/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 1.5400 - val_accuracy: 0.8751\n",
      "\n",
      "Epoch 00190: val_accuracy did not improve from 0.90591\n",
      "Epoch 191/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.5276 - val_accuracy: 0.8738\n",
      "\n",
      "Epoch 00191: val_accuracy did not improve from 0.90591\n",
      "Epoch 192/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 1.5397 - val_accuracy: 0.8731\n",
      "\n",
      "Epoch 00192: val_accuracy did not improve from 0.90591\n",
      "Epoch 193/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 1.5782 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00193: val_accuracy did not improve from 0.90591\n",
      "Epoch 194/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 1.5674 - val_accuracy: 0.8725\n",
      "\n",
      "Epoch 00194: val_accuracy did not improve from 0.90591\n",
      "Epoch 195/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0016 - accuracy: 0.9995 - val_loss: 1.5720 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00195: val_accuracy did not improve from 0.90591\n",
      "Epoch 196/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 0.0019 - accuracy: 0.9995 - val_loss: 1.5813 - val_accuracy: 0.8716\n",
      "\n",
      "Epoch 00196: val_accuracy did not improve from 0.90591\n",
      "Epoch 197/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 1.5682 - val_accuracy: 0.8745\n",
      "\n",
      "Epoch 00197: val_accuracy did not improve from 0.90591\n",
      "Epoch 198/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 1.6203 - val_accuracy: 0.8713\n",
      "\n",
      "Epoch 00198: val_accuracy did not improve from 0.90591\n",
      "Epoch 199/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.4530e-04 - accuracy: 0.9998 - val_loss: 1.6265 - val_accuracy: 0.8718\n",
      "\n",
      "Epoch 00199: val_accuracy did not improve from 0.90591\n",
      "Epoch 200/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.6837 - val_accuracy: 0.8700\n",
      "\n",
      "Epoch 00200: val_accuracy did not improve from 0.90591\n",
      "Epoch 201/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.8738e-04 - accuracy: 0.9998 - val_loss: 1.6119 - val_accuracy: 0.8747\n",
      "\n",
      "Epoch 00201: val_accuracy did not improve from 0.90591\n",
      "Epoch 202/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 1.6739 - val_accuracy: 0.8689\n",
      "\n",
      "Epoch 00202: val_accuracy did not improve from 0.90591\n",
      "Epoch 203/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 1.6946 - val_accuracy: 0.8673\n",
      "\n",
      "Epoch 00203: val_accuracy did not improve from 0.90591\n",
      "Epoch 204/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 1.6276 - val_accuracy: 0.8716\n",
      "\n",
      "Epoch 00204: val_accuracy did not improve from 0.90591\n",
      "Epoch 205/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.6817 - val_accuracy: 0.8691\n",
      "\n",
      "Epoch 00205: val_accuracy did not improve from 0.90591\n",
      "Epoch 206/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 8.8020e-04 - accuracy: 0.9999 - val_loss: 1.6404 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00206: val_accuracy did not improve from 0.90591\n",
      "Epoch 207/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 8.8467e-04 - accuracy: 0.9999 - val_loss: 1.6444 - val_accuracy: 0.8671\n",
      "\n",
      "Epoch 00207: val_accuracy did not improve from 0.90591\n",
      "Epoch 208/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 1.6504 - val_accuracy: 0.8727\n",
      "\n",
      "Epoch 00208: val_accuracy did not improve from 0.90591\n",
      "Epoch 209/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.6501 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00209: val_accuracy did not improve from 0.90591\n",
      "Epoch 210/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.8334e-04 - accuracy: 0.9999 - val_loss: 1.7023 - val_accuracy: 0.8678\n",
      "\n",
      "Epoch 00210: val_accuracy did not improve from 0.90591\n",
      "Epoch 211/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 8.5933e-04 - accuracy: 0.9998 - val_loss: 1.7010 - val_accuracy: 0.8713\n",
      "\n",
      "Epoch 00211: val_accuracy did not improve from 0.90591\n",
      "Epoch 212/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.7096 - val_accuracy: 0.8722\n",
      "\n",
      "Epoch 00212: val_accuracy did not improve from 0.90591\n",
      "Epoch 213/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.6681 - val_accuracy: 0.8729\n",
      "\n",
      "Epoch 00213: val_accuracy did not improve from 0.90591\n",
      "Epoch 214/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.1069e-04 - accuracy: 0.9998 - val_loss: 1.6940 - val_accuracy: 0.8736\n",
      "\n",
      "Epoch 00214: val_accuracy did not improve from 0.90591\n",
      "Epoch 215/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 1.7125 - val_accuracy: 0.8693\n",
      "\n",
      "Epoch 00215: val_accuracy did not improve from 0.90591\n",
      "Epoch 216/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 1.6907 - val_accuracy: 0.8727\n",
      "\n",
      "Epoch 00216: val_accuracy did not improve from 0.90591\n",
      "Epoch 217/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 1.7192 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00217: val_accuracy did not improve from 0.90591\n",
      "Epoch 218/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 7.8412e-04 - accuracy: 0.9998 - val_loss: 1.7089 - val_accuracy: 0.8734\n",
      "\n",
      "Epoch 00218: val_accuracy did not improve from 0.90591\n",
      "Epoch 219/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 8.4926e-04 - accuracy: 0.9998 - val_loss: 1.7156 - val_accuracy: 0.8716\n",
      "\n",
      "Epoch 00219: val_accuracy did not improve from 0.90591\n",
      "Epoch 220/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 8.7103e-04 - accuracy: 0.9999 - val_loss: 1.6992 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00220: val_accuracy did not improve from 0.90591\n",
      "Epoch 221/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 7.1862e-04 - accuracy: 0.9999 - val_loss: 1.8579 - val_accuracy: 0.8635\n",
      "\n",
      "Epoch 00221: val_accuracy did not improve from 0.90591\n",
      "Epoch 222/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 8.1557e-04 - accuracy: 0.9998 - val_loss: 1.7147 - val_accuracy: 0.8745\n",
      "\n",
      "Epoch 00222: val_accuracy did not improve from 0.90591\n",
      "Epoch 223/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.7232 - val_accuracy: 0.8725\n",
      "\n",
      "Epoch 00223: val_accuracy did not improve from 0.90591\n",
      "Epoch 224/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 7.0102e-04 - accuracy: 0.9999 - val_loss: 1.7032 - val_accuracy: 0.8725\n",
      "\n",
      "Epoch 00224: val_accuracy did not improve from 0.90591\n",
      "Epoch 225/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 1.7345 - val_accuracy: 0.8709\n",
      "\n",
      "Epoch 00225: val_accuracy did not improve from 0.90591\n",
      "Epoch 226/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 1.7632 - val_accuracy: 0.8713\n",
      "\n",
      "Epoch 00226: val_accuracy did not improve from 0.90591\n",
      "Epoch 227/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 7.3952e-04 - accuracy: 0.9998 - val_loss: 1.7761 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00227: val_accuracy did not improve from 0.90591\n",
      "Epoch 228/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 7.2296e-04 - accuracy: 0.9999 - val_loss: 1.7468 - val_accuracy: 0.8689\n",
      "\n",
      "Epoch 00228: val_accuracy did not improve from 0.90591\n",
      "Epoch 229/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 1.8048 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00229: val_accuracy did not improve from 0.90591\n",
      "Epoch 230/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.6125e-04 - accuracy: 0.9997 - val_loss: 1.7746 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00230: val_accuracy did not improve from 0.90591\n",
      "Epoch 231/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 6.8177e-04 - accuracy: 0.9999 - val_loss: 1.7912 - val_accuracy: 0.8689\n",
      "\n",
      "Epoch 00231: val_accuracy did not improve from 0.90591\n",
      "Epoch 232/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 1.8116 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00232: val_accuracy did not improve from 0.90591\n",
      "Epoch 233/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.2625e-04 - accuracy: 0.9997 - val_loss: 1.8189 - val_accuracy: 0.8673\n",
      "\n",
      "Epoch 00233: val_accuracy did not improve from 0.90591\n",
      "Epoch 234/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 6.6155e-04 - accuracy: 0.9997 - val_loss: 1.7967 - val_accuracy: 0.8696\n",
      "\n",
      "Epoch 00234: val_accuracy did not improve from 0.90591\n",
      "Epoch 235/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 6.3157e-04 - accuracy: 0.9999 - val_loss: 1.8440 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00235: val_accuracy did not improve from 0.90591\n",
      "Epoch 236/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 7.4357e-04 - accuracy: 0.9998 - val_loss: 1.8059 - val_accuracy: 0.8713\n",
      "\n",
      "Epoch 00236: val_accuracy did not improve from 0.90591\n",
      "Epoch 237/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.9716e-04 - accuracy: 1.0000 - val_loss: 1.7893 - val_accuracy: 0.8711\n",
      "\n",
      "Epoch 00237: val_accuracy did not improve from 0.90591\n",
      "Epoch 238/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6949e-04 - accuracy: 0.9998 - val_loss: 1.8435 - val_accuracy: 0.8709\n",
      "\n",
      "Epoch 00238: val_accuracy did not improve from 0.90591\n",
      "Epoch 239/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.0897e-04 - accuracy: 0.9998 - val_loss: 1.8437 - val_accuracy: 0.8682\n",
      "\n",
      "Epoch 00239: val_accuracy did not improve from 0.90591\n",
      "Epoch 240/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.3981e-04 - accuracy: 0.9999 - val_loss: 1.8347 - val_accuracy: 0.8685\n",
      "\n",
      "Epoch 00240: val_accuracy did not improve from 0.90591\n",
      "Epoch 241/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 7.0950e-04 - accuracy: 0.9998 - val_loss: 1.8197 - val_accuracy: 0.8693\n",
      "\n",
      "Epoch 00241: val_accuracy did not improve from 0.90591\n",
      "Epoch 242/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 8.4310e-04 - accuracy: 0.9997 - val_loss: 1.8580 - val_accuracy: 0.8682\n",
      "\n",
      "Epoch 00242: val_accuracy did not improve from 0.90591\n",
      "Epoch 243/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 8.6279e-04 - accuracy: 0.9998 - val_loss: 1.8958 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00243: val_accuracy did not improve from 0.90591\n",
      "Epoch 244/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.5457e-04 - accuracy: 0.9999 - val_loss: 1.8717 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00244: val_accuracy did not improve from 0.90591\n",
      "Epoch 245/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.1413e-04 - accuracy: 0.9999 - val_loss: 1.8662 - val_accuracy: 0.8693\n",
      "\n",
      "Epoch 00245: val_accuracy did not improve from 0.90591\n",
      "Epoch 246/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.5643e-04 - accuracy: 1.0000 - val_loss: 1.9099 - val_accuracy: 0.8696\n",
      "\n",
      "Epoch 00246: val_accuracy did not improve from 0.90591\n",
      "Epoch 247/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.8848e-04 - accuracy: 0.9999 - val_loss: 1.8753 - val_accuracy: 0.8687\n",
      "\n",
      "Epoch 00247: val_accuracy did not improve from 0.90591\n",
      "Epoch 248/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 6.1895e-04 - accuracy: 0.9999 - val_loss: 1.9320 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00248: val_accuracy did not improve from 0.90591\n",
      "Epoch 249/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.2869e-04 - accuracy: 0.9999 - val_loss: 1.8849 - val_accuracy: 0.8693\n",
      "\n",
      "Epoch 00249: val_accuracy did not improve from 0.90591\n",
      "Epoch 250/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.1056e-04 - accuracy: 0.9997 - val_loss: 1.9082 - val_accuracy: 0.8691\n",
      "\n",
      "Epoch 00250: val_accuracy did not improve from 0.90591\n",
      "Epoch 251/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.9431 - val_accuracy: 0.8702\n",
      "\n",
      "Epoch 00251: val_accuracy did not improve from 0.90591\n",
      "Epoch 252/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5255e-04 - accuracy: 0.9999 - val_loss: 1.9319 - val_accuracy: 0.8680\n",
      "\n",
      "Epoch 00252: val_accuracy did not improve from 0.90591\n",
      "Epoch 253/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.4061e-04 - accuracy: 1.0000 - val_loss: 1.9289 - val_accuracy: 0.8693\n",
      "\n",
      "Epoch 00253: val_accuracy did not improve from 0.90591\n",
      "Epoch 254/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 8.9793e-04 - accuracy: 0.9996 - val_loss: 1.9978 - val_accuracy: 0.8667\n",
      "\n",
      "Epoch 00254: val_accuracy did not improve from 0.90591\n",
      "Epoch 255/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.1602e-04 - accuracy: 0.9998 - val_loss: 1.9986 - val_accuracy: 0.8651\n",
      "\n",
      "Epoch 00255: val_accuracy did not improve from 0.90591\n",
      "Epoch 256/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.0729e-04 - accuracy: 1.0000 - val_loss: 1.9424 - val_accuracy: 0.8682\n",
      "\n",
      "Epoch 00256: val_accuracy did not improve from 0.90591\n",
      "Epoch 257/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 1.9628 - val_accuracy: 0.8687\n",
      "\n",
      "Epoch 00257: val_accuracy did not improve from 0.90591\n",
      "Epoch 258/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 1.9624 - val_accuracy: 0.8691\n",
      "\n",
      "Epoch 00258: val_accuracy did not improve from 0.90591\n",
      "Epoch 259/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.4308e-04 - accuracy: 1.0000 - val_loss: 1.9911 - val_accuracy: 0.8662\n",
      "\n",
      "Epoch 00259: val_accuracy did not improve from 0.90591\n",
      "Epoch 260/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.4319e-04 - accuracy: 1.0000 - val_loss: 1.9734 - val_accuracy: 0.8693\n",
      "\n",
      "Epoch 00260: val_accuracy did not improve from 0.90591\n",
      "Epoch 261/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 7.7245e-04 - accuracy: 0.9997 - val_loss: 2.0889 - val_accuracy: 0.8633\n",
      "\n",
      "Epoch 00261: val_accuracy did not improve from 0.90591\n",
      "Epoch 262/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.2352e-04 - accuracy: 0.9999 - val_loss: 2.0298 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00262: val_accuracy did not improve from 0.90591\n",
      "Epoch 263/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.0584e-04 - accuracy: 0.9999 - val_loss: 1.9876 - val_accuracy: 0.8671\n",
      "\n",
      "Epoch 00263: val_accuracy did not improve from 0.90591\n",
      "Epoch 264/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.2342e-04 - accuracy: 0.9998 - val_loss: 1.9824 - val_accuracy: 0.8718\n",
      "\n",
      "Epoch 00264: val_accuracy did not improve from 0.90591\n",
      "Epoch 265/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 6.0289e-04 - accuracy: 0.9998 - val_loss: 2.0693 - val_accuracy: 0.8611\n",
      "\n",
      "Epoch 00265: val_accuracy did not improve from 0.90591\n",
      "Epoch 266/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7507e-04 - accuracy: 0.9999 - val_loss: 2.0172 - val_accuracy: 0.8707\n",
      "\n",
      "Epoch 00266: val_accuracy did not improve from 0.90591\n",
      "Epoch 267/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.0565e-04 - accuracy: 0.9999 - val_loss: 2.0194 - val_accuracy: 0.8705\n",
      "\n",
      "Epoch 00267: val_accuracy did not improve from 0.90591\n",
      "Epoch 268/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.1101e-04 - accuracy: 0.9999 - val_loss: 2.0281 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00268: val_accuracy did not improve from 0.90591\n",
      "Epoch 269/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.6127e-04 - accuracy: 0.9999 - val_loss: 2.0278 - val_accuracy: 0.8687\n",
      "\n",
      "Epoch 00269: val_accuracy did not improve from 0.90591\n",
      "Epoch 270/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.1589e-04 - accuracy: 0.9999 - val_loss: 2.0894 - val_accuracy: 0.8622\n",
      "\n",
      "Epoch 00270: val_accuracy did not improve from 0.90591\n",
      "Epoch 271/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7051e-04 - accuracy: 0.9999 - val_loss: 2.0613 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00271: val_accuracy did not improve from 0.90591\n",
      "Epoch 272/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 6.4410e-04 - accuracy: 0.9998 - val_loss: 2.1007 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00272: val_accuracy did not improve from 0.90591\n",
      "Epoch 273/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.9011e-04 - accuracy: 0.9998 - val_loss: 2.0546 - val_accuracy: 0.8680\n",
      "\n",
      "Epoch 00273: val_accuracy did not improve from 0.90591\n",
      "Epoch 274/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5624e-04 - accuracy: 0.9999 - val_loss: 2.0921 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00274: val_accuracy did not improve from 0.90591\n",
      "Epoch 275/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.1659e-04 - accuracy: 0.9999 - val_loss: 2.0780 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00275: val_accuracy did not improve from 0.90591\n",
      "Epoch 276/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.7919e-04 - accuracy: 0.9998 - val_loss: 2.1015 - val_accuracy: 0.8647\n",
      "\n",
      "Epoch 00276: val_accuracy did not improve from 0.90591\n",
      "Epoch 277/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.6635e-04 - accuracy: 0.9997 - val_loss: 2.0842 - val_accuracy: 0.8629\n",
      "\n",
      "Epoch 00277: val_accuracy did not improve from 0.90591\n",
      "Epoch 278/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.1837e-04 - accuracy: 0.9996 - val_loss: 2.0908 - val_accuracy: 0.8642\n",
      "\n",
      "Epoch 00278: val_accuracy did not improve from 0.90591\n",
      "Epoch 279/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.9067e-04 - accuracy: 0.9998 - val_loss: 2.0939 - val_accuracy: 0.8685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00279: val_accuracy did not improve from 0.90591\n",
      "Epoch 280/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.1458e-04 - accuracy: 0.9999 - val_loss: 2.1400 - val_accuracy: 0.8640\n",
      "\n",
      "Epoch 00280: val_accuracy did not improve from 0.90591\n",
      "Epoch 281/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.5984e-04 - accuracy: 1.0000 - val_loss: 2.1303 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00281: val_accuracy did not improve from 0.90591\n",
      "Epoch 282/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.6358e-04 - accuracy: 1.0000 - val_loss: 2.1122 - val_accuracy: 0.8673\n",
      "\n",
      "Epoch 00282: val_accuracy did not improve from 0.90591\n",
      "Epoch 283/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 6.0158e-04 - accuracy: 0.9998 - val_loss: 2.1256 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00283: val_accuracy did not improve from 0.90591\n",
      "Epoch 284/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.0367e-04 - accuracy: 0.9999 - val_loss: 2.1854 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00284: val_accuracy did not improve from 0.90591\n",
      "Epoch 285/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.1647e-04 - accuracy: 0.9999 - val_loss: 2.2379 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00285: val_accuracy did not improve from 0.90591\n",
      "Epoch 286/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.1025e-04 - accuracy: 1.0000 - val_loss: 2.1517 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00286: val_accuracy did not improve from 0.90591\n",
      "Epoch 287/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.9851e-04 - accuracy: 0.9999 - val_loss: 2.1677 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00287: val_accuracy did not improve from 0.90591\n",
      "Epoch 288/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 6.8646e-04 - accuracy: 0.9998 - val_loss: 2.1961 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00288: val_accuracy did not improve from 0.90591\n",
      "Epoch 289/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.2115e-04 - accuracy: 1.0000 - val_loss: 2.2455 - val_accuracy: 0.8644\n",
      "\n",
      "Epoch 00289: val_accuracy did not improve from 0.90591\n",
      "Epoch 290/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.8041e-04 - accuracy: 1.0000 - val_loss: 2.1853 - val_accuracy: 0.8680\n",
      "\n",
      "Epoch 00290: val_accuracy did not improve from 0.90591\n",
      "Epoch 291/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.3520e-04 - accuracy: 1.0000 - val_loss: 2.2303 - val_accuracy: 0.8635\n",
      "\n",
      "Epoch 00291: val_accuracy did not improve from 0.90591\n",
      "Epoch 292/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.0435e-04 - accuracy: 0.9998 - val_loss: 2.2072 - val_accuracy: 0.8662\n",
      "\n",
      "Epoch 00292: val_accuracy did not improve from 0.90591\n",
      "Epoch 293/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.7163e-04 - accuracy: 0.9999 - val_loss: 2.1998 - val_accuracy: 0.8642\n",
      "\n",
      "Epoch 00293: val_accuracy did not improve from 0.90591\n",
      "Epoch 294/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.5524e-04 - accuracy: 1.0000 - val_loss: 2.2104 - val_accuracy: 0.8678\n",
      "\n",
      "Epoch 00294: val_accuracy did not improve from 0.90591\n",
      "Epoch 295/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.7892e-04 - accuracy: 0.9999 - val_loss: 2.2383 - val_accuracy: 0.8631\n",
      "\n",
      "Epoch 00295: val_accuracy did not improve from 0.90591\n",
      "Epoch 296/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.7018e-04 - accuracy: 0.9997 - val_loss: 2.2564 - val_accuracy: 0.8635\n",
      "\n",
      "Epoch 00296: val_accuracy did not improve from 0.90591\n",
      "Epoch 297/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.2267e-04 - accuracy: 1.0000 - val_loss: 2.2674 - val_accuracy: 0.8642\n",
      "\n",
      "Epoch 00297: val_accuracy did not improve from 0.90591\n",
      "Epoch 298/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.7050e-04 - accuracy: 1.0000 - val_loss: 2.2590 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00298: val_accuracy did not improve from 0.90591\n",
      "Epoch 299/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.8963e-04 - accuracy: 1.0000 - val_loss: 2.2472 - val_accuracy: 0.8664\n",
      "\n",
      "Epoch 00299: val_accuracy did not improve from 0.90591\n",
      "Epoch 300/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.6183e-04 - accuracy: 1.0000 - val_loss: 2.2626 - val_accuracy: 0.8658\n",
      "\n",
      "Epoch 00300: val_accuracy did not improve from 0.90591\n",
      "Epoch 301/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.3970e-04 - accuracy: 1.0000 - val_loss: 2.2507 - val_accuracy: 0.8651\n",
      "\n",
      "Epoch 00301: val_accuracy did not improve from 0.90591\n",
      "Epoch 302/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.9575e-04 - accuracy: 0.9998 - val_loss: 2.2448 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00302: val_accuracy did not improve from 0.90591\n",
      "Epoch 303/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.7982e-04 - accuracy: 0.9999 - val_loss: 2.2412 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00303: val_accuracy did not improve from 0.90591\n",
      "Epoch 304/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 8.3607e-04 - accuracy: 0.9998 - val_loss: 2.2973 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00304: val_accuracy did not improve from 0.90591\n",
      "Epoch 305/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6589e-04 - accuracy: 1.0000 - val_loss: 2.3020 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00305: val_accuracy did not improve from 0.90591\n",
      "Epoch 306/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.5312e-04 - accuracy: 0.9999 - val_loss: 2.3153 - val_accuracy: 0.8622\n",
      "\n",
      "Epoch 00306: val_accuracy did not improve from 0.90591\n",
      "Epoch 307/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.1209e-04 - accuracy: 0.9999 - val_loss: 2.2830 - val_accuracy: 0.8642\n",
      "\n",
      "Epoch 00307: val_accuracy did not improve from 0.90591\n",
      "Epoch 308/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8147e-04 - accuracy: 1.0000 - val_loss: 2.2956 - val_accuracy: 0.8595\n",
      "\n",
      "Epoch 00308: val_accuracy did not improve from 0.90591\n",
      "Epoch 309/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.6288e-04 - accuracy: 0.9998 - val_loss: 2.3375 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00309: val_accuracy did not improve from 0.90591\n",
      "Epoch 310/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 2.0956e-04 - accuracy: 1.0000 - val_loss: 2.3071 - val_accuracy: 0.8629\n",
      "\n",
      "Epoch 00310: val_accuracy did not improve from 0.90591\n",
      "Epoch 311/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 2.8638e-04 - accuracy: 0.9999 - val_loss: 2.3149 - val_accuracy: 0.8649\n",
      "\n",
      "Epoch 00311: val_accuracy did not improve from 0.90591\n",
      "Epoch 312/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 3.8229e-04 - accuracy: 0.9997 - val_loss: 2.3234 - val_accuracy: 0.8660\n",
      "\n",
      "Epoch 00312: val_accuracy did not improve from 0.90591\n",
      "Epoch 313/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.7656e-04 - accuracy: 0.9999 - val_loss: 2.3770 - val_accuracy: 0.8611\n",
      "\n",
      "Epoch 00313: val_accuracy did not improve from 0.90591\n",
      "Epoch 314/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5875e-04 - accuracy: 1.0000 - val_loss: 2.3756 - val_accuracy: 0.8613\n",
      "\n",
      "Epoch 00314: val_accuracy did not improve from 0.90591\n",
      "Epoch 315/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5081e-04 - accuracy: 1.0000 - val_loss: 2.3412 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00315: val_accuracy did not improve from 0.90591\n",
      "Epoch 316/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5785e-04 - accuracy: 1.0000 - val_loss: 2.3720 - val_accuracy: 0.8647\n",
      "\n",
      "Epoch 00316: val_accuracy did not improve from 0.90591\n",
      "Epoch 317/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 4.9549e-04 - accuracy: 0.9999 - val_loss: 2.4146 - val_accuracy: 0.8611\n",
      "\n",
      "Epoch 00317: val_accuracy did not improve from 0.90591\n",
      "Epoch 318/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.6994e-04 - accuracy: 1.0000 - val_loss: 2.3622 - val_accuracy: 0.8624\n",
      "\n",
      "Epoch 00318: val_accuracy did not improve from 0.90591\n",
      "Epoch 319/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.3157e-04 - accuracy: 0.9999 - val_loss: 2.3776 - val_accuracy: 0.8653\n",
      "\n",
      "Epoch 00319: val_accuracy did not improve from 0.90591\n",
      "Epoch 320/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.5966e-04 - accuracy: 0.9999 - val_loss: 2.3819 - val_accuracy: 0.8629\n",
      "\n",
      "Epoch 00320: val_accuracy did not improve from 0.90591\n",
      "Epoch 321/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.2640e-04 - accuracy: 0.9998 - val_loss: 2.3922 - val_accuracy: 0.8613\n",
      "\n",
      "Epoch 00321: val_accuracy did not improve from 0.90591\n",
      "Epoch 322/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.9917e-04 - accuracy: 0.9999 - val_loss: 2.3957 - val_accuracy: 0.8622\n",
      "\n",
      "Epoch 00322: val_accuracy did not improve from 0.90591\n",
      "Epoch 323/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1157e-04 - accuracy: 1.0000 - val_loss: 2.4019 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00323: val_accuracy did not improve from 0.90591\n",
      "Epoch 324/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 2.4373e-04 - accuracy: 1.0000 - val_loss: 2.4474 - val_accuracy: 0.8613\n",
      "\n",
      "Epoch 00324: val_accuracy did not improve from 0.90591\n",
      "Epoch 325/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.9531e-04 - accuracy: 0.9998 - val_loss: 2.4603 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00325: val_accuracy did not improve from 0.90591\n",
      "Epoch 326/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.0100e-04 - accuracy: 0.9998 - val_loss: 2.4318 - val_accuracy: 0.8624\n",
      "\n",
      "Epoch 00326: val_accuracy did not improve from 0.90591\n",
      "Epoch 327/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.4561e-04 - accuracy: 1.0000 - val_loss: 2.4340 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00327: val_accuracy did not improve from 0.90591\n",
      "Epoch 328/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.4851e-04 - accuracy: 1.0000 - val_loss: 2.4016 - val_accuracy: 0.8669\n",
      "\n",
      "Epoch 00328: val_accuracy did not improve from 0.90591\n",
      "Epoch 329/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.6911e-04 - accuracy: 1.0000 - val_loss: 2.4558 - val_accuracy: 0.8615\n",
      "\n",
      "Epoch 00329: val_accuracy did not improve from 0.90591\n",
      "Epoch 330/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.8919e-04 - accuracy: 0.9999 - val_loss: 2.4772 - val_accuracy: 0.8609\n",
      "\n",
      "Epoch 00330: val_accuracy did not improve from 0.90591\n",
      "Epoch 331/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.2488e-04 - accuracy: 1.0000 - val_loss: 2.4430 - val_accuracy: 0.8656\n",
      "\n",
      "Epoch 00331: val_accuracy did not improve from 0.90591\n",
      "Epoch 332/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1029e-04 - accuracy: 1.0000 - val_loss: 2.4653 - val_accuracy: 0.8613\n",
      "\n",
      "Epoch 00332: val_accuracy did not improve from 0.90591\n",
      "Epoch 333/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.2729e-04 - accuracy: 0.9999 - val_loss: 2.4969 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00333: val_accuracy did not improve from 0.90591\n",
      "Epoch 334/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0496e-04 - accuracy: 1.0000 - val_loss: 2.5398 - val_accuracy: 0.8631\n",
      "\n",
      "Epoch 00334: val_accuracy did not improve from 0.90591\n",
      "Epoch 335/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8678e-04 - accuracy: 0.9999 - val_loss: 2.4653 - val_accuracy: 0.8638\n",
      "\n",
      "Epoch 00335: val_accuracy did not improve from 0.90591\n",
      "Epoch 336/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.8011e-04 - accuracy: 1.0000 - val_loss: 2.4462 - val_accuracy: 0.8629\n",
      "\n",
      "Epoch 00336: val_accuracy did not improve from 0.90591\n",
      "Epoch 337/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.1857e-04 - accuracy: 0.9998 - val_loss: 2.5468 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00337: val_accuracy did not improve from 0.90591\n",
      "Epoch 338/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.7590e-04 - accuracy: 0.9999 - val_loss: 2.4930 - val_accuracy: 0.8651\n",
      "\n",
      "Epoch 00338: val_accuracy did not improve from 0.90591\n",
      "Epoch 339/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.8011e-04 - accuracy: 0.9999 - val_loss: 2.5067 - val_accuracy: 0.8640\n",
      "\n",
      "Epoch 00339: val_accuracy did not improve from 0.90591\n",
      "Epoch 340/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.3100e-04 - accuracy: 1.0000 - val_loss: 2.4935 - val_accuracy: 0.8613\n",
      "\n",
      "Epoch 00340: val_accuracy did not improve from 0.90591\n",
      "Epoch 341/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8567e-04 - accuracy: 1.0000 - val_loss: 2.5253 - val_accuracy: 0.8644\n",
      "\n",
      "Epoch 00341: val_accuracy did not improve from 0.90591\n",
      "Epoch 342/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 6.1271e-04 - accuracy: 0.9996 - val_loss: 2.5239 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00342: val_accuracy did not improve from 0.90591\n",
      "Epoch 343/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.7356e-04 - accuracy: 0.9998 - val_loss: 2.5426 - val_accuracy: 0.8629\n",
      "\n",
      "Epoch 00343: val_accuracy did not improve from 0.90591\n",
      "Epoch 344/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.4395e-04 - accuracy: 0.9999 - val_loss: 2.5299 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00344: val_accuracy did not improve from 0.90591\n",
      "Epoch 345/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.8928e-04 - accuracy: 0.9999 - val_loss: 2.5508 - val_accuracy: 0.8600\n",
      "\n",
      "Epoch 00345: val_accuracy did not improve from 0.90591\n",
      "Epoch 346/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.2883e-04 - accuracy: 1.0000 - val_loss: 2.5946 - val_accuracy: 0.8584\n",
      "\n",
      "Epoch 00346: val_accuracy did not improve from 0.90591\n",
      "Epoch 347/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.1332e-04 - accuracy: 1.0000 - val_loss: 2.5678 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00347: val_accuracy did not improve from 0.90591\n",
      "Epoch 348/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.2500e-05 - accuracy: 1.0000 - val_loss: 2.6143 - val_accuracy: 0.8595\n",
      "\n",
      "Epoch 00348: val_accuracy did not improve from 0.90591\n",
      "Epoch 349/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.2826e-04 - accuracy: 1.0000 - val_loss: 2.5568 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00349: val_accuracy did not improve from 0.90591\n",
      "Epoch 350/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.5548e-04 - accuracy: 0.9999 - val_loss: 2.6040 - val_accuracy: 0.8613\n",
      "\n",
      "Epoch 00350: val_accuracy did not improve from 0.90591\n",
      "Epoch 351/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.4309e-04 - accuracy: 1.0000 - val_loss: 2.5949 - val_accuracy: 0.8627\n",
      "\n",
      "Epoch 00351: val_accuracy did not improve from 0.90591\n",
      "Epoch 352/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.1089e-04 - accuracy: 0.9999 - val_loss: 2.6092 - val_accuracy: 0.8598\n",
      "\n",
      "Epoch 00352: val_accuracy did not improve from 0.90591\n",
      "Epoch 353/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.3894e-04 - accuracy: 0.9999 - val_loss: 2.6213 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00353: val_accuracy did not improve from 0.90591\n",
      "Epoch 354/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.8487e-04 - accuracy: 0.9999 - val_loss: 2.5944 - val_accuracy: 0.8618\n",
      "\n",
      "Epoch 00354: val_accuracy did not improve from 0.90591\n",
      "Epoch 355/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.3194e-04 - accuracy: 1.0000 - val_loss: 2.6221 - val_accuracy: 0.8613\n",
      "\n",
      "Epoch 00355: val_accuracy did not improve from 0.90591\n",
      "Epoch 356/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0925e-04 - accuracy: 0.9999 - val_loss: 2.6167 - val_accuracy: 0.8595\n",
      "\n",
      "Epoch 00356: val_accuracy did not improve from 0.90591\n",
      "Epoch 357/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.6933e-04 - accuracy: 0.9999 - val_loss: 2.6649 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00357: val_accuracy did not improve from 0.90591\n",
      "Epoch 358/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5555e-04 - accuracy: 1.0000 - val_loss: 2.6464 - val_accuracy: 0.8627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00358: val_accuracy did not improve from 0.90591\n",
      "Epoch 359/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.4511e-04 - accuracy: 1.0000 - val_loss: 2.6545 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00359: val_accuracy did not improve from 0.90591\n",
      "Epoch 360/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.2625e-04 - accuracy: 0.9999 - val_loss: 2.6577 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00360: val_accuracy did not improve from 0.90591\n",
      "Epoch 361/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.0611e-04 - accuracy: 1.0000 - val_loss: 2.7064 - val_accuracy: 0.8595\n",
      "\n",
      "Epoch 00361: val_accuracy did not improve from 0.90591\n",
      "Epoch 362/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8995e-04 - accuracy: 1.0000 - val_loss: 2.6792 - val_accuracy: 0.8591\n",
      "\n",
      "Epoch 00362: val_accuracy did not improve from 0.90591\n",
      "Epoch 363/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.8826e-04 - accuracy: 1.0000 - val_loss: 2.7244 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00363: val_accuracy did not improve from 0.90591\n",
      "Epoch 364/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.1005e-04 - accuracy: 1.0000 - val_loss: 2.7257 - val_accuracy: 0.8609\n",
      "\n",
      "Epoch 00364: val_accuracy did not improve from 0.90591\n",
      "Epoch 365/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.4967e-04 - accuracy: 1.0000 - val_loss: 2.7494 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00365: val_accuracy did not improve from 0.90591\n",
      "Epoch 366/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.0078e-04 - accuracy: 1.0000 - val_loss: 2.7096 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00366: val_accuracy did not improve from 0.90591\n",
      "Epoch 367/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9166e-04 - accuracy: 1.0000 - val_loss: 2.6888 - val_accuracy: 0.8647\n",
      "\n",
      "Epoch 00367: val_accuracy did not improve from 0.90591\n",
      "Epoch 368/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 8.6067e-05 - accuracy: 1.0000 - val_loss: 2.6822 - val_accuracy: 0.8606\n",
      "\n",
      "Epoch 00368: val_accuracy did not improve from 0.90591\n",
      "Epoch 369/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.3841e-05 - accuracy: 1.0000 - val_loss: 2.7737 - val_accuracy: 0.8580\n",
      "\n",
      "Epoch 00369: val_accuracy did not improve from 0.90591\n",
      "Epoch 370/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9896e-04 - accuracy: 0.9999 - val_loss: 2.7397 - val_accuracy: 0.8582\n",
      "\n",
      "Epoch 00370: val_accuracy did not improve from 0.90591\n",
      "Epoch 371/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.8287e-04 - accuracy: 0.9999 - val_loss: 2.7411 - val_accuracy: 0.8598\n",
      "\n",
      "Epoch 00371: val_accuracy did not improve from 0.90591\n",
      "Epoch 372/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5424e-04 - accuracy: 1.0000 - val_loss: 2.7393 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00372: val_accuracy did not improve from 0.90591\n",
      "Epoch 373/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.4734e-04 - accuracy: 1.0000 - val_loss: 2.7535 - val_accuracy: 0.8591\n",
      "\n",
      "Epoch 00373: val_accuracy did not improve from 0.90591\n",
      "Epoch 374/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.2571e-04 - accuracy: 1.0000 - val_loss: 2.7668 - val_accuracy: 0.8629\n",
      "\n",
      "Epoch 00374: val_accuracy did not improve from 0.90591\n",
      "Epoch 375/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.4509e-04 - accuracy: 1.0000 - val_loss: 2.7406 - val_accuracy: 0.8595\n",
      "\n",
      "Epoch 00375: val_accuracy did not improve from 0.90591\n",
      "Epoch 376/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 6.5656e-05 - accuracy: 1.0000 - val_loss: 2.7541 - val_accuracy: 0.8573\n",
      "\n",
      "Epoch 00376: val_accuracy did not improve from 0.90591\n",
      "Epoch 377/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.5212e-04 - accuracy: 0.9999 - val_loss: 2.7875 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00377: val_accuracy did not improve from 0.90591\n",
      "Epoch 378/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.4461e-04 - accuracy: 1.0000 - val_loss: 2.7702 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00378: val_accuracy did not improve from 0.90591\n",
      "Epoch 379/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.0651e-05 - accuracy: 1.0000 - val_loss: 2.7928 - val_accuracy: 0.8595\n",
      "\n",
      "Epoch 00379: val_accuracy did not improve from 0.90591\n",
      "Epoch 380/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 9.7564e-05 - accuracy: 1.0000 - val_loss: 2.8092 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00380: val_accuracy did not improve from 0.90591\n",
      "Epoch 381/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 6.9991e-05 - accuracy: 1.0000 - val_loss: 2.7912 - val_accuracy: 0.8586\n",
      "\n",
      "Epoch 00381: val_accuracy did not improve from 0.90591\n",
      "Epoch 382/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.2647e-05 - accuracy: 1.0000 - val_loss: 2.8371 - val_accuracy: 0.8589\n",
      "\n",
      "Epoch 00382: val_accuracy did not improve from 0.90591\n",
      "Epoch 383/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.9615e-04 - accuracy: 1.0000 - val_loss: 2.7933 - val_accuracy: 0.8591\n",
      "\n",
      "Epoch 00383: val_accuracy did not improve from 0.90591\n",
      "Epoch 384/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 8.0745e-05 - accuracy: 1.0000 - val_loss: 2.8513 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00384: val_accuracy did not improve from 0.90591\n",
      "Epoch 385/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.3899e-04 - accuracy: 0.9999 - val_loss: 2.8547 - val_accuracy: 0.8586\n",
      "\n",
      "Epoch 00385: val_accuracy did not improve from 0.90591\n",
      "Epoch 386/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 9.4300e-05 - accuracy: 1.0000 - val_loss: 2.8117 - val_accuracy: 0.8618\n",
      "\n",
      "Epoch 00386: val_accuracy did not improve from 0.90591\n",
      "Epoch 387/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.5881e-04 - accuracy: 1.0000 - val_loss: 2.8261 - val_accuracy: 0.8620\n",
      "\n",
      "Epoch 00387: val_accuracy did not improve from 0.90591\n",
      "Epoch 388/400\n",
      "1122/1122 [==============================] - 4s 3ms/step - loss: 1.2178e-04 - accuracy: 1.0000 - val_loss: 2.8444 - val_accuracy: 0.8595\n",
      "\n",
      "Epoch 00388: val_accuracy did not improve from 0.90591\n",
      "Epoch 389/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 7.2704e-05 - accuracy: 1.0000 - val_loss: 2.8935 - val_accuracy: 0.8569\n",
      "\n",
      "Epoch 00389: val_accuracy did not improve from 0.90591\n",
      "Epoch 390/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8435e-05 - accuracy: 1.0000 - val_loss: 2.8658 - val_accuracy: 0.8582\n",
      "\n",
      "Epoch 00390: val_accuracy did not improve from 0.90591\n",
      "Epoch 391/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.0958e-04 - accuracy: 1.0000 - val_loss: 2.8603 - val_accuracy: 0.8582\n",
      "\n",
      "Epoch 00391: val_accuracy did not improve from 0.90591\n",
      "Epoch 392/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 4.8848e-05 - accuracy: 1.0000 - val_loss: 2.9117 - val_accuracy: 0.8593\n",
      "\n",
      "Epoch 00392: val_accuracy did not improve from 0.90591\n",
      "Epoch 393/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.1631e-04 - accuracy: 0.9999 - val_loss: 2.9026 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00393: val_accuracy did not improve from 0.90591\n",
      "Epoch 394/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 8.0513e-05 - accuracy: 1.0000 - val_loss: 2.8854 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00394: val_accuracy did not improve from 0.90591\n",
      "Epoch 395/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.2035e-04 - accuracy: 1.0000 - val_loss: 2.8886 - val_accuracy: 0.8611\n",
      "\n",
      "Epoch 00395: val_accuracy did not improve from 0.90591\n",
      "Epoch 396/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 5.8087e-05 - accuracy: 1.0000 - val_loss: 2.9130 - val_accuracy: 0.8580\n",
      "\n",
      "Epoch 00396: val_accuracy did not improve from 0.90591\n",
      "Epoch 397/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 7.6916e-05 - accuracy: 1.0000 - val_loss: 2.9318 - val_accuracy: 0.8560\n",
      "\n",
      "Epoch 00397: val_accuracy did not improve from 0.90591\n",
      "Epoch 398/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1122/1122 [==============================] - 3s 3ms/step - loss: 3.5869e-04 - accuracy: 0.9999 - val_loss: 2.8969 - val_accuracy: 0.8604\n",
      "\n",
      "Epoch 00398: val_accuracy did not improve from 0.90591\n",
      "Epoch 399/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 2.4874e-04 - accuracy: 0.9998 - val_loss: 2.9267 - val_accuracy: 0.8571\n",
      "\n",
      "Epoch 00399: val_accuracy did not improve from 0.90591\n",
      "Epoch 400/400\n",
      "1122/1122 [==============================] - 3s 3ms/step - loss: 1.0302e-04 - accuracy: 1.0000 - val_loss: 2.8886 - val_accuracy: 0.8602\n",
      "\n",
      "Epoch 00400: val_accuracy did not improve from 0.90591\n"
     ]
    }
   ],
   "source": [
    "model_history = InceptionV3_model.fit(train_inception,ytrain,validation_data = (valid_inception, ytest),epochs=400, batch_size=16, shuffle=True, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbafd84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 12))\n",
    "ax1.plot(model_history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(model_history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, 400, 1))\n",
    "ax1.set_yticks(np.arange(0, 1, 0.1))\n",
    "\n",
    "ax2.plot(model_history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(model_history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xticks(np.arange(1, 400, 1))\n",
    "\n",
    "legend = plt.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22a473b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, figsize = (10,7), fontsize=14):\n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=\"d\")\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    fig.savefig(os.path.join(MODEL_PATH,\"confusion_matrix.png\"))\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b7a2674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_heatmap(n_labels, n_predictions, class_names):\n",
    "    labels = n_labels #sess.run(tf.argmax(n_labels, 1))\n",
    "    predictions = n_predictions #sess.run(tf.argmax(n_predictions, 1))\n",
    "\n",
    "#     confusion_matrix = sess.run(tf.contrib.metrics.confusion_matrix(labels, predictions))\n",
    "    matrix = confusion_matrix(labels.argmax(axis=1),predictions.argmax(axis=1))\n",
    "    row_sum = np.sum(matrix, axis = 1)\n",
    "    w, h = matrix.shape\n",
    "\n",
    "    c_m = np.zeros((w, h))\n",
    "\n",
    "    for i in range(h):\n",
    "        c_m[i] = matrix[i] * 100 / row_sum[i]\n",
    "\n",
    "    c = c_m.astype(dtype = np.uint8)\n",
    "\n",
    "    \n",
    "    heatmap = print_confusion_matrix(c, class_names, figsize=(18,10), fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86aac1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "class_names = list()\n",
    "for name,idx in labels_id.items():\n",
    "    class_names.append(name)\n",
    "# print(class_names)\n",
    "ypred = InceptionV3_model.predict(valid_inception,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c786f4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA78AAAJhCAYAAACJowdxAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABpm0lEQVR4nO3debxUdf348df73osbrqiIgGtmormjueS+lSumaf3UtEUzbbFSs9IsbXfJzG8hWqmUJGZKKqKpuKBCYKIiLriVIO4ooMhy7+f3xxnsDrHcyzBz5sx9PX2cx9yZOTPz5u3nzMxn3p/P50RKCUmSJEmSGllT3gFIkiRJklRtdn4lSZIkSQ3Pzq8kSZIkqeHZ+ZUkSZIkNTw7v5IkSZKkhmfnV5IkSZLU8FryDmBZe//+wZ67qQJr7H923iEUWmtba94hFF5zU3PeIagL8xiWis3PkMr5PliZObMnR94xLCtz33i+Zv2qbmttXJO8WfmVJEmSJDU8O7+SJEmSpIbXcMOeJUmSJEkVasAh8FZ+JUmSJEkNz8qvJEmSJKlcass7gmXOyq8kSZIkqeFZ+ZUkSZIklWuz8itJkiRJUuFY+ZUkSZIklUnO+ZUkSZIkqXis/EqSJEmSyjnnV5IkSZKk4rHyK0mSJEkq55xfSZIkSZKKx8qvJEmSJKlcW2veESxzVn4lSZIkSQ3Pyq8kSZIkqZxzfiVJkiRJKh47v5IkSZKkhuewZ0mSJElSuTaHPVdNRPSNiD9ExMsRMTsiXoyISyJijbxjkyRJkiQVW110fiPiQ8DDwOeBfwK/Ap4HvgE8FBFr5hjeUht8xxgO/8FAPvWDy/nOoL8xe+48Lr7+Tg47+3ccee4gTvu/65n+3vt5h1kIffuuy4gRf+GRR+7i4Yf/wamnfj7vkApn0OUXMvml8TzyrzvzDqWQbIOVMX+V8xiujPmrnDmsjO+DlbH91V5KbTXbaqUuOr/Ab4GewNdTSgNSSmellPYm6wR/BPhJrtEthVenTefau//JkLO/yN/O+zJtbYkR/3yCnTbfiBt+9GX++qOT2GCdHvx++AN5h1oI8+a1ctZZP2bbbfdhjz0G8OUvf47NNvtw3mEVyjWDr+fgQ47NO4zCsg1WxvxVzmO4MuavcuawMr4PVsb2p2Wh6p3fiNgxIq6LiCml4cxTI+KOiDiqdP/GwP7Ai8D/LfDwc4F3geMionu1Y13WWlvbmD1nHvNa25g1Zy5rr74yu2zxIVqas7RvtXEfXps2Pecoi+GVV15j/PgJAMyc+S5PPfUsvXuvk3NUxTJq1BimTXs77zAKyzZYGfNXOY/hypi/ypnDyvg+WBnbXw7a2mq31UhVF7yKiBOB3wGtwN+BSWQV3v7AKcBQYO/S7nekBWreKaUZEfEAWed4J+Cuasa7LK2zxqocf8DOHPCdS1mhWzd23mIjdtniQ2X73DTqUQ7YYfOcIiyu9dfvyzbbbMHYsePzDkVdlG2wMuZPUlfn+6CUj6p1fiNic7LhzNOB3VJKTyxwf9/Snx8pXT6ziKeaRNb53ZQCdX6nvzuLkeOfZvjPv8oqK67AGQNv4JaHHufgnbcE4IpbRtHc3MRBO30050iLpXv3lRgyZCBnnHEeM2bMzDscdUG2wcqYP0ldne+DKowazsWtlWoOe/4KWef6/AU7vgAppcmlP1crXb6ziOeZf/vqi3qhiDgpIsZFxLjf/33kUoa7bI1+8gX6rLU6PVbpTreWZvbZbjMefS77J//9gUe577FJ/OxLA4iInCMtjpaWFoYMGch1193EsGEj8g5HXZBtsDLmT1JX5/uglK9qDnveqXR5W4XPM793mBa1Q0ppEDAI4P37By9yv1rq1WM1Hnt+CrNmz2WF5VoY8+QLbL5hbx6Y8Bx/HPEQvz/zOFZcvlveYRbKwIG/5Omnn+XSS6/MOxR1UbbBypg/SV2d74MqlLbWvCNY5qpZ+V29dDllCfvNr+yutoj7V11gv0LYauM+7Ld9Pz5z/pUcce4g2lLiyN235Wd/HsG778/m5Iuv5agfXcH5g4fnHWoh7LJLf4455gj22GMXRo8ezujRwznggL3yDqtQBl9zGffdO4xNN/0Qzz83lhNO+EzeIRWKbbAy5q9yHsOVMX+VM4eV8X2wMrY/LQuRUnUKpRExlmxhq34ppacWs9+XgCuAQSmlLy/k/tvJ5vzum1Ja4pzfeqn8FtUa+5+ddwiF1tqAv5DVWnNTc94hqAvzGJaKzc+Qyvk+WJk5syc3zJzG2U+OrFm/avl+e9Ukb9Ws/I4uXX5yCfvNn6S7f0SUxRMRqwC7ArPaPZ8kSZIkSZ1Szc7v74B5wDmllZ/LzF/tOaX0HHAHsCFw6gK7/QjoDlyTUnq3irFKkiRJkubzPL8dl1KaGBGnAAOBRyJiGNlpi9YkGw49A5g/0eEU4EHg0ojYB3gS+Fjp/meA71crTkmSJElS46vmas+klK6IiAnA6cCewADgDeAx4Mp2+z0XEf2B84BPAAcCU4FLgR+llN6qZpySJEmSpHYa8Dy/Ve38AqSUHgKO6MB+LwGfr3Y8kiRJkqSup5pzfiVJkiRJqgtVr/xKkiRJkgqmhgtR1YqVX0mSJElSw7PyK0mSJEkqk1Jr3iEsc1Z+JUmSJEkNz8qvJEmSJKlcA57qyMqvJEmSJKnhWfmVJEmSJJVztWdJkiRJkorHyq8kSZIkqZxzfiVJkiRJKh4rv5IkSZKkcm2e51eSJEmSpMKx8itJkiRJKuecX0mSJEmSisfKryRJkiSpnOf5lSRJkiSpeOz8SpIkSZIaXsMNe155n7PyDqHQZr18f94hFNqq6+2VdwiFN7d1Xt4hFFpTRN4hFFpbSnmHUHi2wcrYBivT5meItOy44JUkSZIkScXTcJVfSZIkSVKFXPBKkiRJkqTisfIrSZIkSSpn5VeSJEmSpOKx8itJkiRJKpNSa94hLHNWfiVJkiRJDc/KryRJkiSpnHN+JUmSJEkqHiu/kiRJkqRyycqvJEmSJEmFY+VXkiRJklTOOb+SJEmSJNVORHwzIp6IiAkRMSQiVoiIHhHxj4iYVLpcY0nPY+dXkiRJklQutdVuW4yI6AN8HeifUvoo0Ax8BjgLuCul9GHgrtL1xbLzK0mSJEmqZy3AihHRAqwEvAwcBlxduv9qYMCSnsTOryRJkiSpLqWUpgAXAv8BpgLvpJTuANZJKU0t7TMV6Lmk53LBK0mSJElSuRoueBURJwEntbtpUEppUOm+NciqvBsBbwPXR8SxS/M6dn4lSZIkSbkpdXQHLeLufYEXUkqvA0TE34BdgFcjYt2U0tSIWBd4bUmvY+dXkiRJklRuCQtR1dB/gJ0iYiVgFrAPMA54Fzge+HnpctiSnsjOryRJkiSpLqWUxkTEX4F/AfOAR8iqxCsDQyPii2Qd5E8v6bly7/xGxJrA4cBBwJZAH2AO8DjwR+CPKdXPzw6SJEmS1PBqOOd3SVJK5wLnLnDzbLIqcIfl3vkl66H/jmzlrpFkvfZ1gE8BVwKfjIhPp5RSfiFKkiRJkoqsHk519AxwKNA3pXRMSum7KaUvAJsBLwFHkHWEC++A/ffkiQn38dTEUZx5xql5h1MIg4fexIBjT+awY77M4OtuBODCy67kkM+eyOGf+wpf/+55TJ8xM+co61/fvusyYsRfeOSRu3j44X9w6qmfzzukQvIYXnqDLr+QyS+N55F/3Zl3KIVl+6uMbbBytsHKmL/KmcMaa2ur3VYjVe/8RsSOEXFdREyJiNkRMTUi7oiIowBSSnenlG5ecGhzSukVYGDp6p7VjrPampqauPTXP+HgQ45ly6334uijB9Cv34fzDquuTXr+RW74+wiGXHkJN1z9W+598J/8+6Up7LzDttw4eCA3XvM7NlyvD1cOvi7vUOvevHmtnHXWj9l2233YY48BfPnLn2OzzWx/neExXJlrBl/PwYcs1VkJhO1vWbANVsY2WBnzVzlzqGWhqp3fiDgReBAYULq8CLiV7ATEp3TgKeaWLudVI75a2nGHbXnuuRd54YX/MHfuXIYOHcahhxyQd1h17fkXX2KrLTZjxRVWoKWlmf7bbMld9z3Irh/bnpaWZgC22mIzXn3tjZwjrX+vvPIa48dPAGDmzHd56qln6d17nZyjKhaP4cqMGjWGadPezjuMwrL9Vc42WBnbYGXMX+XMYQ5SW+22Gqla5zciNgd+C0wHtkspfTql9L2U0pdSStsAi/35NSJagM+Vro6oVpy10rtPL16a/PIH1ydPmUrv3r1yjKj+bbLxBjz86ATefmc6s95/n/sfGssrr75ets+Nt97Bx3feIacIi2n99fuyzTZbMHbs+LxDKRSPYeXJ9qe82QYrY/4qZw61LFRzwauvlJ7//JTSEwvemVKavITH/xz4KDA8pXR7FeKrqYj4n9tcw2vxPrTh+nzhmE9z4mnfY6UVV2TTTTamubn5g/svv3oIzc3NHLz/XjlGWSzdu6/EkCEDOeOM85jhXOlO8RhWnmx/ypttsDLmr3LmMAd1tNrzslLNzu9OpcvbOvvAiPg68G3gKeC4Dux/EnASQDSvRlNT986+ZNVNmTyV9fr2/uB63z7rMnXqqzlGVAxHHHIAR5SGtFwy8Cp69VwLgGHD/8F9D/yTKy/92ULfDPW/WlpaGDJkINdddxPDhhV+MEXNeQwrT7Y/5c02WBnzVzlzqGWhmnN+Vy9dTunMgyLiVODXwERgr5TSW0t6TEppUEqpf0qpfz12fAHGjhvPJptsxIYbrke3bt046qjDuPmWO/IOq+69WZqfNfWV17jr3gf45L57MGr0OH7/5+v5zS/OZcUVVsg3wAIZOPCXPP30s1x66ZV5h1JIHsPKk+1PebMNVsb8Vc4c5qAB5/xWs/L7dumyD1kFd4ki4jTgV8AEYJ+U0mtViSwHra2tfOO0sxl+67U0NzVx1dXXMXHiM3mHVfe++b0f8/b06bS0tPD9b5/Caquuwk8u/i1z5s7lxNO+D2SLXp175tdyjrS+7bJLf4455ggef/xJRo8eDsC5517A7bePzDmy4vAYrszgay5j9913Zq21evD8c2M57/yLuOqqv+QdVmHY/ipnG6yMbbAy5q9y5lDLQlRrrHxE/Ab4KvCtlNKvOrD/d8jm+Y4H9kspLdUSvi3L9XHwfwVmvXx/3iEU2qrrOf+4UnNbC7+4e66anAZQkTbnj1XMNlgZ26BUbPPmTGmYN8FZN/68Zm9IKx5+Vk3yVs1hz78jO0XROaWVn8tERN92f59D1vF9mKzi67lrJEmSJEnLTNWGPaeUJkbEKcBA4JGIGAZMAtYE+gMzgL0i4njgPKAVuB/4+kIWMHoxpXRVtWKVJEmSJDW2as75JaV0RURMAE4H9gQGAG8AjwHzV93ZqHTZDJy2iKe6F7iqSmFKkiRJktqr4UJUtVLVzi9ASukh4IjF3P9D4IfVjkOSJEmS1HVVvfMrSZIkSSqYtsar/FZzwStJkiRJkuqClV9JkiRJUjkrv5IkSZIkFY+VX0mSJElSuZTyjmCZs/IrSZIkSWp4Vn4lSZIkSeWc8ytJkiRJUvFY+ZUkSZIklbPyK0mSJElS8Vj5lSRJkiSVS1Z+JUmSJEkqHCu/kiRJkqRyzvmVJEmSJKl47PxKkiRJkhqew54lSZIkSeVSyjuCZc7KryRJkiSp4Vn5lSRJkiSVa8AFrxqu89utueH+STW15gb75h1Cob111RfyDqHwVjluUN4hFNoKLcvlHYK6uJam5rxDKLR5ba15h1Bo78+bk3cIkuqYPUVJkiRJUrkGrPw651eSJEmS1PCs/EqSJEmSyiUrv5IkSZIkFY6VX0mSJElSmdTmeX4lSZIkSSocK7+SJEmSpHKu9ixJkiRJUvFY+ZUkSZIklXO1Z0mSJEmSisfKryRJkiSpnKs9S5IkSZJUPHZ+JUmSJEkNz2HPkiRJkqRynupIkiRJkqTisfIrSZIkSSpn5VeSJEmSpOKx8itJkiRJKpc81ZEkSZIkSYVj5VeSJEmSVM45v5IkSZIkFU/ddH4j4qCIuCMiJkfErIh4PiKuj4id845NkiRJkrqUtlS7rUbqYthzRPwCOBN4E7gJeAPYBDgMOCIiPpdS+lN+EVaub991ufLKX7HOOmvT1tbGH/5wLf/3f3/MO6zCWH755Rhxx3Ust/xytDQ3M+ymEfz0J5fkHVZde/GN6Zw5dNQH16dMm8lX9tqKY3fZjCGjn+YvY56huamJ3TbtzTcP2DbHSIvjgP335OKLz6O5qYk//HEIv7zg//IOqTA8hitj/paNpqYm7r7vRqZOfZXPfvqkvMMpFNtg5QZdfiEHHrgvr7/+Bttut2/e4RSO+dOyECnnVbwiohcwBXgd2Cql9Fq7+/YC7gZeSClt3JHnW3HFDepyWbJevXrSq1dPxo+fwMord+fBB2/hqKNO4qmnJuUdWpluTc15h7BI3buvxLvvvkdLSwt33DmU75xxHmPHjs87rDKv/uH4vENYqNa2Nva/8CYGn3QAU96ayZX3TeA3x+7Jci3NvDXzfXqsvELeIX5gleMG5R3CQjU1NfHkE/fziQM/y+TJUxn90HCOPe4Unnyyvo7hlbotn3cIi1SEY7ieFSV/LXX8OXLKVz/PNttuySqrrly3nd95ba15h7BIRWiD78+bk3cIi/Txj3+MmTPf5Y9/uMTO21IoSv7mzJ4cecewrLx3wRdq1q9a6Yw/1CRvVR/2HBE7RsR1ETElImZHxNTS8OajSrtsUIpjTPuOL0BKaSQwA1i72nFW2yuvvMb48RMAmDnzXZ566ll6914n56iK5d133wOgW7cWWrq1kPcPN0Uy5vlX6bvGyvRevTtDx07i87ttwXIt2RfUeur41rMdd9iW5557kRde+A9z585l6NBhHHrIAXmHVSgew5Uxf5Xp3bsX+x2wJ4OvHpp3KIVlG6zMqFFjmDbt7bzDKCzzp2Whqp3fiDgReBAYULq8CLgV6AmcUtptEjAH2DEi1lrg8bsDqwB3VjPOWlt//b5ss80Wdfdrab1rampi1EO38NyLYxl59wOMG/do3iEVxu2P/5tPbrUBAP9+czr/+vdrHHv57Xzx93cyYcqbOUdXDL379OKlyS9/cH3ylKn07t0rx4iKx2O4MuavMj/9xff54Tm/pK0BVy+tFdug1MU04JzfqnV+I2Jz4LfAdGC7lNKnU0rfSyl9KaW0DXAsQErpLeA7wDrAxIgYFBE/i4ihwB3AP4AvVyvOWuvefSWGDBnIGWecx4wZM/MOp1Da2tr4+M4H02/TXdh++63ot/mmeYdUCHPntXLv01PYb4v1AWhtS8yYNYfBJ+3PaQdsw5nXjfLX+w6I+N/ROOatczyGK2P+lt7+n9iL119/k0fHP5F3KIVmG5RUdNWs/H6FbEGt81NK//Npk1Ka3O7vS4BPlfY/ETgL+DTwEnDVgsOhFxQRJ0XEuIgYN29e/XYoW1paGDJkINdddxPDho3IO5zCeuedGYy6fwz77rd73qEUwqhJU9ls3TVYc+UVAVhn1ZXYe/P1iAi27LsWTRFMe292zlHWvymTp7Je394fXO/bZ12mTn01x4iKy2O4Muav8z6203Z88sB9GD9hJFdedQm77b4TA6+4MO+wCss2KHUNqa2tZlutVLPzu1Pp8rYl7RgRZwJ/Ba4CPgR0B7YHngf+HBG/XNzjU0qDUkr9U0r9W1pWrijoaho48Jc8/fSzXHrplXmHUjhrrtWD1VZbBYAVVliePffalUlPP59zVMUw4vEX+cSWG3xwfa9+fRn7fNZp+/cb05nb2sYaK9XvIkn1Yuy48WyyyUZsuOF6dOvWjaOOOoybb7kj77AKw2O4MuavMuf/8CI+utlubPPRvfjSCadx/32jOfnE0/MOq1Bsg5IaQTVPdbR66XLK4naKiD2BXwA3ppS+1e6uf0XE4cAzwLcjYmBKqbDvsrvs0p9jjjmCxx9/ktGjhwNw7rkXcPvtI3OOrBh69erJwEEX0NzcTFNTcOMNwxkx4u68w6p7s+bMY/Rzr3D2oTt+cNuAbTfm3JvGcMRlt9KtuYnzP7XTQof0qlxrayvfOO1sht96Lc1NTVx19XVMnPhM3mEVhsdwZcyf8mYbrNzgay5j9913Zq21evD8c2M57/yLuOqqv+QdVmGYvxzUcC5urVTtVEcRMRboD/RLKT21mP0uBL4NfD2l9JuF3P834HDgyJTSDUt63Xo91VFR1POpjoqgXk91VCT1eqqjoqjnUx2pa6jnUx0VQT2f6qgI6vlUR+oaGulUR+/+5HM161d1//41hT/V0ejS5SeXsN/8b2qLOp3R/Nt9N5MkSZIkLZVqdn5/B8wDzimt/FwmIvqW/ry/dHlSRPRZYJ9PArsC75OdKkmSJEmSVG2prXZbjVRtzm9KaWJEnAIMBB6JiGFk5/Rdk2w49AxgL7KFru4E9gWejIgbgVeAfsDBQABnpZQ8GakkSZIkaalUc8ErUkpXRMQE4HRgT2AA8AbwGHBlaZ+2iDgQOBX4DNn83pWAt4DhwKUpJZdUlSRJkqRaacAFr6ra+QVIKT0EHLGEfeYCl5Q2SZIkSZKWqap3fiVJkiRJBdNWu7m4tVLNBa8kSZIkSaoLVn4lSZIkSeUacM6vlV9JkiRJUsOz8itJkiRJKlfD8+/WipVfSZIkSVLDs/IrSZIkSSrnnF9JkiRJkorHyq8kSZIkqUzyPL+SJEmSJBWPlV9JkiRJUjnn/EqSJEmSVDx2fiVJkiRJDc9hz5IkSZKkcg57liRJkiSpeKz8SpIkSZLKJU91JEmSJElS4Vj5lSRJkiSVa8A5vw3X+W1ta807hEKb2zov7xAKbZXjBuUdQuHNeunuvEMotBXX2zvvENTFNUXkHYIkSQvVcJ1fSZIkSVJlUgNWfp3zK0mSJElqeFZ+JUmSJEnlrPxKkiRJklQ8Vn4lSZIkSeXaPM+vJEmSJEmFY+VXkiRJklTOOb+SJEmSJBWPlV9JkiRJUjkrv5IkSZIkFY+dX0mSJElSw3PYsyRJkiSpTEoOe5YkSZIkqXCs/EqSJEmSyrnglSRJkiRJxWPlV5IkSZJUzsqvJEmSJEnFY+VXkiRJklQmWfmVJEmSJKl4rPxKkiRJkspZ+a2OiHgxItIitlfyjk+SJEmSVGx10fkteQf40UK2C/MMalkZdPmFTH5pPI/86868QymsA/bfkycm3MdTE0dx5hmn5h1O4Zi/zht8/d8ZcPxXOexzpzJ46DAAbh85isM+dypb7nEYE56alHOExWIbrIz5q4yfw5Uzh5Uxf5Uxfzloq+HWARGxekT8NSKeiognI2LniOgREf+IiEmlyzUW9xz11Pl9O6X0w4VsDdH5vWbw9Rx8yLF5h1FYTU1NXPrrn3DwIcey5dZ7cfTRA+jX78N5h1UY5q/zJj3/b2645Q6GXH4RN/zhUu59aBz/fullNtloAy758XfZfust8g6xUGyDlTF/lfNzuHLmsDLmrzLmT8CvgREppc2ArYEngbOAu1JKHwbuKl1fpKp3fiNix4i4LiKmRMTsiJgaEXdExFHVfu16MmrUGKZNezvvMAprxx225bnnXuSFF/7D3LlzGTp0GIceckDeYRWG+eu85//9Eltt/hFWXGF5Wlqa6b/NFtx1/0N8aMP12Gj9vnmHVzi2wcqYv8r5OVw5c1gZ81cZ81d7qS3VbFuSiFgV2B34PUBKaU5K6W3gMODq0m5XAwMW9zxV7fxGxInAg6UgHgQuAm4FegKnLLD78hFxbER8LyK+ERF7RURzNeNTcfTu04uXJr/8wfXJU6bSu3evHCMqFvPXeZtstAEPP/oEb78znVnvz+b+0Q/zymtv5B1WYdkGK2P+JEld3MbA68AfI+KRiLgyIroD66SUpgKULnsu7kmqttpzRGwO/BaYDuyWUnpigfsXLJ30AgYvcNsLEfH5lNK91YpTxRAR/3NbSo23Al21mL/O+9CG6/GF//cpTvzWD1hpxRXY9EMb0dzs73FLyzZYGfMnSaq5Gq72HBEnASe1u2lQSmlQu+stwHbA11JKYyLi1yxhiPPCVPNUR18pPf/5C3Z8AVJKk9td/SNwP/AEMIOsZ/9VsgTcFhE7p5QeXdQLtU9Wc/PqNDV3X2b/CNWHKZOnsl7f3h9c79tnXaZOfTXHiIrF/C2dIw7enyMO3h+ASwZdQ6+118o5ouKyDVbG/EmSGlmpoztoMbtMBianlMaUrv+VrPP7akSsm1KaGhHrAq8t7nWqOex5p9LlbUvaMaX0o5TS3SmlV1NK76WUJqSUTgYuBlYEfriExw9KKfVPKfW349uYxo4bzyabbMSGG65Ht27dOOqow7j5ljvyDqswzN/SebM0t2jqq69z130P8cl9d883oAKzDVbG/EmSurKU0ivASxHxkdJN+wATgb8Dx5duOx4YtrjnqWbnd/XS5ZQKnmNg6bLw3zgHX3MZ9907jE03/RDPPzeWE074TN4hFUprayvfOO1sht96LRMeu4e//vVmJk58Ju+wCsP8LZ1vnvNzDj3uVE4963y+/82TWW2VlbnzvofY54jP8+gTT3HKd87jpG+fm3eYhWAbrIz5q5yfw5Uzh5Uxf5Uxfzmos1MdAV8D/hwRjwHbAD8Ffg7sFxGTgP1K1xcpqjVnKCLGAv2Bfimlp5byOVYlO//v7JTSCh15zHLL93USVAXanEOmnM166e68Qyi0FdfbO+8Q1MU1LWR+siR1FXNmT26YN8G3j96rZh2D1a8bWZO8VXPO72iyzu8ngaXq/AI7ly6fXyYRSZIkSZKWqCOnICqaag57/h0wDzintPJzmfmrPUfEFhHRYyH3bwBcVrr6pyrGKUmSJElqcFWr/KaUJkbEKWTzdh+JiGHAJGBNsorwDGAv4NPAWRExEnihdPuHgIOAFYDhwIXVilOSJEmStICOz8UtjGoOeyaldEVETABOB/YEBgBvAI8BV5Z2Gwl8BNiWbJhzd+BtYBTZeX8HJ09mKEmSJEmqQFU7vwAppYeAIxZz/73AvdWOQ5IkSZLUMc75lSRJkiSpgKpe+ZUkSZIkFUwDzvm18itJkiRJanhWfiVJkiRJZZKVX0mSJEmSisfKryRJkiSpnJVfSZIkSZKKx8qvJEmSJKmMc34lSZIkSSogO7+SJEmSpIbnsGdJkiRJUjmHPUuSJEmSVDxWfiVJkiRJZVzwSpIkSZKkArLyK0mSJEkqY+VXkiRJkqQCsvIrSZIkSSpj5VeSJEmSpAJquMrvait0zzuEQps2a2beIRRat+aGO6RqbsX19s47hEKbedfP8w6h0Fbd97t5h1B4bSnlHYK6sJW6LZ93CIU3t6017xBUL1LkHcEyZ+VXkiRJktTwLFNJkiRJkso451eSJEmSpAKy8itJkiRJKpPanPMrSZIkSVLhWPmVJEmSJJVxzq8kSZIkSQVk51eSJEmS1PAc9ixJkiRJKpOSC15JkiRJklQ4Vn4lSZIkSWVc8EqSJEmSpAKy8itJkiRJKpPanPMrSZIkSVLhWPmVJEmSJJVJKe8Ilj0rv5IkSZKkhmflV5IkSZJUxjm/kiRJkiQVkJVfSZIkSVIZK7+SJEmSJBVQXXR+I/OFiBgdETMi4r2IeCQivh4RzXnHJ0mSJEldSUq122qlLjq/wNXA74GNgOuAK4DlgF8D10VE49XcJUmSJEk1k3vnNyIGAMcBLwBbpJS+lFL6BrANcBNwBHB8XvEtSw8/dhf3Pvh3Rt5/E/+454a8wymcA/bfkycm3MdTE0dx5hmn5h1OofTtuy4jRvyFRx65i4cf/gennvr5vEMqJNtg5w2+YwyH/2Agn/rB5Xxn0N+YPXceF19/J4ed/TuOPHcQp/3f9Ux/7/28wyyEQZdfyOSXxvPIv+7MO5TC8hiujPlbessvvxwj772RB0bfypixI/je90/LO6TC8btM7aW2qNlWK5GqXGeOiB2BbwMfB9YC3gIeB65MKQ2NiGvIOr9fTSn93wKP/Whp33+llLbvyOutvdpH6vZ0zA8/dhf77Xkkb701Le9QFmnarJl5h7BQTU1NPPnE/XziwM8yefJURj80nGOPO4Unn5yUd2hlujXX5xpyvXr1pFevnowfP4GVV+7Ogw/ewlFHncRTT9VX/gDmts7LO4SFKkobnHnXz/MO4QOvTpvOCb+4mhvPO5kVluvGGQNv4ONbbsLaq6/MjpttREtzE7/6610AfPPIfXKONrPqvt/NO4RF+vjHP8bMme/yxz9cwrbb7Zt3OIvUVsvxa51QlGO4XhUlfyt1Wz7vEBape/eVePfd92hpaeGOO4fynTPOY+zY8XmH9T/mtrXmHcJCFeW7zKxZ/26YEavPb7l/zd7QN378jprkraqV34g4EXgQGFC6vAi4FegJnFLarVfp8vmFPMX827aLiNWrFqjq3o47bMtzz73ICy/8h7lz5zJ06DAOPeSAvMMqjFdeeY3x4ycAMHPmuzz11LP07r1OzlEVi21w6bS2tjF7zjzmtbYxa85c1l59ZXbZ4kO0NGcfP1tt3IfXpk3POcpiGDVqDNOmvZ13GIXlMVwZ81e5d999D4Bu3Vpo6dZCtQtQjcbvMloWqlamiojNgd8C04HdUkpPLHB/39Kfb5QuN1rI02zc7u/NgNHLOs5aSsD1N/2elBJX//E6Bl81NO+QCqN3n168NPnlD65PnjKVHXfYNseIimv99fuyzTZb1OWvzfXMNth566yxKscfsDMHfOdSVujWjZ232IhdtvhQ2T43jXqUA3bYPKcI1ZV4DFfG/FWuqamJ+x74OxtvvAFXDPoT48Y9mndIheV3mdpIqWGK2B+oZuX3K2Sd6/MX7PgCpJQml/68pXT5rYjoMf/+iGgBftTuIWtUK9BaOWj/z7LP7p/iM0ecyBe+dAw779I/75AKY2FrnvmLaed1774SQ4YM5IwzzmPGjPoc4l6vbIOdN/3dWYwc/zTDf/5V/nHhN5g1ey63PPT4B/dfccsompubOGinj+YYpboKj+HKmL/KtbW18fGdD6bfpruw/fZb0W/zTfMOqZD8LqNKVLPzu1Pp8rYl7PeX0j4fAiZGxKCIuAQYDxwIzB/Iv8gJCBFxUkSMi4hx7895u5KYq+rVV14D4I033mL4Lf9g2+23yjmi4pgyeSrr9e39wfW+fdZl6tRXc4yoeFpaWhgyZCDXXXcTw4aNyDucwrENdt7oJ1+gz1qr02OV7nRraWaf7Tbj0eey3z3//sCj3PfYJH72pQEL/VItLWsew5Uxf8vOO+/MYNT9Y9h3v93zDqVw/C5TW6mtdlutVLPzu3rpcsridkoptQGHAqcDr5AtfvUFYDLZIllvlnZ9bTHPMSil1D+l1H+F5VZf1G65WmmlFem+cvcP/t5z7115amJ9TdCvZ2PHjWeTTTZiww3Xo1u3bhx11GHcfMsdeYdVKAMH/pKnn36WSy+9Mu9QCsk22Hm9eqzGY89PYdbsuaSUGPPkC2y07lo8MOE5/jjiIX79taNYcflueYepLsJjuDLmrzJrrtWD1VZbBYAVVliePffalUlPL2y5Gy2O32VUqWouTft26bIP8NTidkwpzSNbDOui9rdHxIpkpzyaBfzP0OkiWbvnmlz1p2wx65aWZv7211u4+677c46qOFpbW/nGaWcz/NZraW5q4qqrr2PixGfyDqswdtmlP8cccwSPP/4ko0cPB+Dccy/g9ttH5hxZcdgGO2+rjfuw3/b9+Mz5V9Lc1MRm66/Dkbtvy6d+cDlz5s3j5IuvBWDLjftwznEH5hxt/Rt8zWXsvvvOrLVWD55/biznnX8RV131l7zDKgyP4cqYv8r06tWTgYMuoLm5maam4MYbhjNixN15h1UofpepvbYGnPNbtVMdRcRvgK8C30op/Wopn+Mk4HLg6pTSCR15TD2f6qgI6vVUR0VRr6c6KpJ6PdVRUdTTqY6KqJ5PdVQU9XqqI3UN9Xyqo6Ko11MdFUUjneromX6fqNkb+qZPjqhJ3hb5Tb3UeV3kPzil9PUlPPfvgJOBcyLi9pTSxAWev+/8Ra8iYtWU0vQF7t8B+DkwEzhvCa8lSZIkSVpGGnG158WVqcZV8sQppYkRcQowEHgkIoaRLV61JtAfmAHsVdr9HxExC5hQun0LssWuZgOfSik5KUKSJEmStNQW2flNKV3d/npEdE8pvduZJ08pXRERE8gWs9oTGEB2Xt/HgPYz1f8KfAY4FlgReLl0/89TSi925jUlSZIkSZVJbV2r8gtAROwM/B5YGVg/IrYGvpxSOqUjL5BSegg4Ygn7XABc0JHnkyRJkiSpszpyqqNLgAMonXIopfQo4InJJEmSJKlBpVS7rVY6dJ7flNJLC9zkMnCSJEmSpMLoyHlZXoqIXYAUEcsBXweerG5YkiRJkqS8NOKc345Ufk8GTgX6AFOAbUrXJUmSJEkqhCVWflNKbwDH1CAWSZIkSVIdaGvA8/wusfIbERtHxM0R8XpEvBYRwyJi41oEJ0mSJEnSstCRYc/XAkOBdYHewPXAkGoGJUmSJEnSstSRzm+klAanlOaVtj8BNVyQWpIkSZJUSylFzbZaWeSc34joUfpzZEScBfyFrNN7NHBrDWKTJEmSJGmZWNyCVw+TdXbnd8W/3O6+BJxfraAkSZIkSflJDTjWd5Gd35TSRrUMRJIkSZKkalniqY4AIuKjwObACvNvSyldU62gJEmSJEn5acRTHS2x8xsR5wJ7knV+hwOfBEYBdn4lSZIkSYXQkcrvkcDWwCMppc9HxDrAldUNS5IkSZKUl1quwlwrHTnV0ayUUhswLyJWBV4DNq5uWJIkSZIkLTsdqfyOi4jVgSvIVoCeCfyzmkFJkiRJkvLTpVZ7ni+ldErpz4ERMQJYNaX0WHXDkiRJkiRp2Vlk5zcitlvcfSmlf1UnJEmSJElSnrraas8XLea+BOy9jGNZJmbOeT/vEAqtKRqvkatYbIOVWXXf7+YdQqHNePiPeYdQeKts//m8Q1AX9v68OXmHUHhtjTjWVSpZZOc3pbRXLQORJEmSJNWHrrrasyRJkiRJhdaR1Z4lSZIkSV1II875tfIrSZIkSWp4S+z8RubYiPhB6fr6EbFj9UOTJEmSJGnZ6Ejl97fAzsBnS9dnAP9XtYgkSZIkSblKNdxqpSNzfj+WUtouIh4BSClNi4jlqhyXJEmSJEnLTEc6v3MjoplSpzwi1gbaqhqVJEmSJCk3XXXBq0uBG4GeEfETYBTw06pGJUmSJEnSMrTEym9K6c8R8TCwDxDAgJTSk1WPTJIkSZKUi9SAld8ldn4jYn3gPeDm9rellP5TzcAkSZIkSVpWOjLn91ay+b4BrABsBDwNbFHFuCRJkiRJOWnERZ46Mux5y/bXI2I74MtVi0iSJEmSpGWsI5XfMimlf0XEDtUIRpIkSZKUv0TXnPP7rXZXm4DtgNerFpEkSZIkSctYRyq/q7T7ex7ZHOAbqhOOJEmSJClvbSnvCJa9xXZ+I6IZWDmldEaN4pEkSZIkaZlbZOc3IlpSSvNKC1xJkiRJkrqIti425/efZPN7x0fE34HrgXfn35lS+luVY5MkSZIkaZnoyJzfHsCbwN7893y/CbDzK0mSJEkNqKut9tyztNLzBP7b6Z2vAac/S5IkSZIa1eI6v83AyrDQLv8y7fxGxJHAHsA2wNZkK0z/OaV07LJ8HUmSJElS19S0mPumppTOSyn9aCHbecs4jrOBr5J1fqcs4+euC337rsuIEX/hkUfu4uGH/8Gpp34+75AKZdDlFzL5pfE88q878w6lkGx/lbMNVsb8LZ3BN9/N4d/4MYef9hPOvPiPzJ4zF4Brh9/DIV87j8O/8WMuvuamfIMsCNtg5cxhZcxf5Q7Yf0+emHAfT00cxZlnnJp3OA2vrYZbrSyu81vLQd7fBDYFVgW+UsPXrZl581o566wfs+22+7DHHgP48pc/x2abfTjvsArjmsHXc/AhDgRYWra/ytkGK2P+Ou/VN9/mz8PvZcgvz+TGS75PW1sbI0Y9zD8ff4aR/3ycGy7+Ljf++myOP2yfvEMtBNtg5cxhZcxfZZqamrj01z/h4EOOZcut9+LoowfQr5/fZdQ5i+v8LpNP04jYMSKui4gpETE7IqZGxB0RcdT8fVJKI1NKk1JKDTuX+JVXXmP8+AkAzJz5Lk899Sy9e6+Tc1TFMWrUGKZNezvvMArL9lc522BlzN/SaW1tZfacucxrbeX9OXNYu8dqDL39fr54+H4s160bAGuutkrOURaDbbBy5rAy5q8yO+6wLc899yIvvPAf5s6dy9Chwzj0kAPyDquhJaJmW60ssvObUnqr0iePiBOBB4EBpcuLgFuBnsAplT5/Ua2/fl+22WYLxo4dn3co6oJsf1IxrLPm6hx/6D7sf/I57POl77PySiuyyzb9+PfU13j4yef4f2ddwOfPuYQJz/4771Alqep69+nFS5Nf/uD65ClT6d27V44RqYg6cqqjpRIRmwO/BaYDu6WUnljg/r7Veu161r37SgwZMpAzzjiPGTNm5h2Ouhjbn1Qc02e+x8ixj3Pbb3/EKt1X4vQLf88t9/6Tea1tzHj3Pf78s9OZ8Oy/Of2iP3Dbb39IROOdkkKS5lvYe1wDDxqtC7Wci1srixv2XKmvkHWuz1+w4wuQUpq8rF4oIk6KiHERMW7evPr9Qt/S0sKQIQO57rqbGDZsRN7hqIux/UnFMvqxp+jbc016rLYK3Vqa2WenrRn/9Auss+bq7POxrYkItvzwhjRFMG16/X72SdKyMGXyVNbr2/uD6337rMvUqa/mGJGKqJqd351Kl7dV8TUASCkNSin1Tyn1b2lZudovt9QGDvwlTz/9LJdeemXeoagLsv1JxdJrrR489swLzJo9h5QSYx5/mo37rsPeO27FPx9/BoAXX36VufPmscaq9fvZJ0nLwthx49lkk43YcMP16NatG0cddRg333JH3mE1tK622nOlVi9dNuSpizprl136c8wxR7DHHrswevRwRo8ezgEH7JV3WIUx+JrLuO/eYWy66Yd4/rmxnHDCZ/IOqVBsf5WzDVbG/HXeVptuyL47b8vRp/+CT33zp6S2xJH77crhe+/M5Nfe/OD0Rz/+2nEOee4A22DlzGFlzF9lWltb+cZpZzP81muZ8Ng9/PWvNzNx4jN5h6WCiWqNlY+IsUB/oF9K6alOPG5PYCTw55RSp9eDX3HFDRz8X4HWtta8Qyi05qbmvEMoPNug8jTj4T/mHULhrbK95xGXiqzNebQVmTdnSsP8GnnrOp+tWWM46NUhNclbNSu/o0uXn6zia0iSJEmSGlxENEfEIxFxS+l6j4j4R0RMKl2usaTnqGbn93fAPOCc0srPZbrqas+SJEmSVO/aonZbB30DeLLd9bOAu1JKHwbuKl1frKqd6iilNDEiTgEGAo9ExDBgErAm2XDoGcBeABExgOxcwADzT9i1c0RcVfr7jZTS6dWKVZIkSZJUn0qF04OAnwDfKt18GLBn6e+rgXuA7yzuearW+QVIKV0REROA00uBDQDeAB4D2i85uw1w/AIP37i0Afy79BySJEmSpCpro66mL18CnAms0u62dVJKUwFSSlMjoueSnqSqnd9SIA8BRyxhnx8CP6x2LJIkSZKk+hIRJwEntbtpUEppUOm+g4HXUkoPlxZHXmpV7/xKkiRJkoqllut+lzq6gxZx967AoRFxILACsGpE/Al4NSLWLVV91wVeW9LrVHPBK0mSJEmSllpK6bsppb4ppQ2BzwB3l06J+3f+O3X2eGDYkp7Lyq8kSZIkqUxb3gEs2c+BoRHxReA/wKeX9AA7v5IkSZKkupdSuodsVWdSSm8C+3Tm8Q57liRJkiQ1PCu/kiRJkqQybVFXpzpaJqz8SpIkSZIanpVfSZIkSVKZWp7qqFas/EqSJEmSGp6VX0mSJElSmQKc6qjTrPxKkiRJkhqelV9JkiRJUpm2xlvs2cqvJEmSJKnxWfmVJEmSJJVpo/FKv1Z+JUmSJEkNz8qvJEmSJKmM5/mVJEmSJKmArPxKkiRJkso04mrPDdf5nds6L+8QCq1bc8M1iZrq1tScdwiF19rWmncIhdaWGnGQUu2ssv3n8w6h8GY8/Me8Qyi07tudkHcIhdYUDfhtvcbMoRqZPR1JkiRJUpm2vAOoAuf8SpIkSZIanp1fSZIkSVLDc9izJEmSJKlMI64iYuVXkiRJktTwrPxKkiRJkso04qmOrPxKkiRJkhqelV9JkiRJUhlPdSRJkiRJUgFZ+ZUkSZIklbHyK0mSJElSAVn5lSRJkiSVSa72LEmSJElS8Vj5lSRJkiSVcc6vJEmSJEkFZOVXkiRJklTGyq8kSZIkSQVk5VeSJEmSVCblHUAVWPmVJEmSJDU8O7+SJEmSpIZXV53fiNgtIm6IiKkRMbt0eUdEHJh3bJIkSZLUVbRF7bZaqZs5vxFxNnA+8AZwCzAVWAvYFtgTGJ5bcJIkSZKkQquLym9EfJqs43snsHFK6fMppe+llE5KKe0AfD/fCJeNA/bfkycm3MdTE0dx5hmn5h1OofTtuy4jRvyFRx65i4cf/gennvr5vEMqlOWXX46R997IA6NvZczYEXzv+6flHVLhDLr8Qia/NJ5H/nVn3qEUlu+BlbENdt7gm+/m8G/8mMNP+wlnXvxHZs+ZC8C1w+/hkK+dx+Hf+DEXX3NTvkEWiMdwZTyGK2P+aq+thlutVL3zGxE7RsR1ETFlgaHMR5XubwJ+AbwH/L+U0owFnyOlNLfacVZbU1MTl/76Jxx8yLFsufVeHH30APr1+3DeYRXGvHmtnHXWj9l2233YY48BfPnLn2OzzcxfR82ePYeDDzyGXXc6iF13Pph999udHXbYJu+wCuWawddz8CHH5h1GYfkeWDnbYOe8+ubb/Hn4vQz55ZnceMn3aWtrY8Soh/nn488w8p+Pc8PF3+XGX5/N8Yftk3eoheAxXDmP4cqYPy0LVe38RsSJwIPAgNLlRcCtQE/glNJuuwAbkQ1rnhYRB0XEdyLiGxGxczXjq6Udd9iW5557kRde+A9z585l6NBhHHrIAXmHVRivvPIa48dPAGDmzHd56qln6d17nZyjKpZ3330PgG7dWmjp1kJKjbiAffWMGjWGadPezjuMwvI9sHK2wc5rbW1l9py5zGtt5f05c1i7x2oMvf1+vnj4fizXrRsAa662Ss5RFoPHcOU8hitj/mqvESu/VZvzGxGbA78FpgO7pZSeWOD+vqU/dyhdvgr8C9hygf3uA45MKb1erVhroXefXrw0+eUPrk+eMpUdd9g2x4iKa/31+7LNNlswduz4vEMplKamJu574O9svPEGXDHoT4wb92jeIakL8T1QtbbOmqtz/KH7sP/J57DCcsux89abscs2/fjV4Jt4+MnnuHTIzSzfrRvfPv5wPrrJBnmHW/c8hiU1gmpWfr9C1rk+f8GOL0BKaXLpz56ly5OBFYF9gVWAjwK3A7sD1y/uhSLipIgYFxHj2treXUbhL1sR/7uMmZW3zuvefSWGDBnIGWecx4wZM/MOp1Da2tr4+M4H02/TXdh++63ot/mmeYekLsT3QNXa9JnvMXLs49z22x9x5xU/Ydb7c7jl3n8yr7WNGe++x59/djrf+twATr/oD7bFDvAYlrqeVMOtVqrZ+d2pdHnbEvZrLl0GWYX3rpTSzFKH+XBgMrDH4oZAp5QGpZT6p5T6NzV1rzjwapgyeSrr9e39wfW+fdZl6tRXc4yoeFpaWhgyZCDXXXcTw4aNyDucwnrnnRmMun8M++63e96hqAvxPVC1Nvqxp+jbc016rLYK3Vqa2WenrRn/9Auss+bq7POxrYkItvzwhjRFMG26P6YuicewpEZQzc7v6qXLKUvYb1rp8vmUUtk4zJTSLLLqL8COyy602hs7bjybbLIRG264Ht26deOoow7j5lvuyDusQhk48Jc8/fSzXHrplXmHUjhrrtWD1Urz2lZYYXn23GtXJj39fM5RqSvxPVC11mutHjz2zAvMmj2HlBJjHn+ajfuuw947bsU/H38GgBdffpW58+axxqor5xxt/fMYlrqeRjzPbzU7v2+XLvssYb+nF9h/QfM7xytWGE+uWltb+cZpZzP81muZ8Ng9/PWvNzNx4jN5h1UYu+zSn2OOOYI99tiF0aOHM3r0cA44YK+8wyqMXr16cstt1/LgmOHcc/9NjLx7FCNG3J13WIUy+JrLuO/eYWy66Yd4/rmxnHDCZ/IOqVB8D6ycbbBzttp0Q/bdeVuOPv0XfOqbPyW1JY7cb1cO33tnJr/25genP/rx145b6JBelfMYrpzHcGXMn5aFqNZ8jYj4DfBV4FsppV8tZr+1gKnAu0DPlNKcBe6/DfgE8NmU0l+W9Loty/VxAkoFujVXbQ20LqFbU/OSd9JivT9vzpJ30iK1OQevIk12gio24+E/5h1CoXXf7oS8Qyg0j2Hlbc7syQ3TCH++wbE1+1Jx1r//VJO8VbPy+ztgHnBOaeXnMvNXe04pvQFcB6wG/GCBffYDDgDeAZzkKUmSJElaKlUr86WUJkbEKcBA4JGIGAZMAtYE+gMzgPnjVr8FfAz4fkTsDvwT2IBswatW4MSU0tvVilWSJEmS9F+NOJasqmNcU0pXRMQE4HRgT2AA8AbwGHBlu/1ei4iPAWeTdXh3Iusc3wr8LKU0uppxSpIkSZIaW9UneKaUHgKO6MB+b5FVgL9V7ZgkSZIkSYvW1oC132rO+ZUkSZIkqS7Y+ZUkSZIkNTzPayNJkiRJKtOWdwBVYOVXkiRJktTwrPxKkiRJkso03nJXVn4lSZIkSV2AlV9JkiRJUhnn/EqSJEmSVEBWfiVJkiRJZdoi7wiWPSu/kiRJkqSGZ+VXkiRJklSmrQHXe7byK0mSJElqeFZ+JUmSJEllGq/ua+VXkiRJktQFWPmVJEmSJJXxPL+SJEmSJBWQlV9JkiRJUhlXe5YkSZIkqYAarvLbFJF3CIXW2taadwiF1q2pOe8Q1MX5Hqi8rbL95/MOodBm/vPyvEMotFU/dnLeIUiqYw3X+ZUkSZIkVabxBj077FmSJEmS1AVY+ZUkSZIklfFUR5IkSZIkFZCVX0mSJElSGU91JEmSJElSAVn5lSRJkiSVaby6r5VfSZIkSVIXYOVXkiRJklTG1Z4lSZIkSSogK7+SJEmSpDKpAWf9WvmVJEmSJDU8K7+SJEmSpDLO+ZUkSZIkqYCs/EqSJEmSyrQ551eSJEmSpOKx8ytJkiRJangOe5YkSZIklWm8Qc9WfiVJkiRJXYCVX0mSJElSGRe8qoKIOCEi0hK21rzjlCRJkiQVVz1UfscDP1rEfbsBewO31SwaSZIkSeri2vIOoApy7/ymlMaTdYD/R0Q8VPpzUK3iqZZBl1/IgQfuy+uvv8G22+2bdziFY/4qs/zyyzHijutYbvnlaGluZthNI/jpTy7JO6xCsQ1WxvxVzhxWxvwtncG33svf7h5DEHx4/V6c95XP8Idhd3PDXaPpserKAHztswey27b9co60/tkGK2P+tCxUfdhzROwYEddFxJSImB0RUyPijog4agmP+yiwEzAFuLXacVbbNYOv5+BDjs07jMIyf5WZPXsOBx94DLvudBC77nww++63OzvssE3eYRWKbbAy5q9y5rAy5q/zXn3rHa69bRRDfvZN/nbRGbS1JUY8+AgAxx20O0N/+W2G/vLbdnw7yDZYGfNXe6mG/9VKVTu/EXEi8CAwoHR5EVlHtidwyhIe/uXS5e9TSoWf8ztq1BimTXs77zAKy/xV7t133wOgW7cWWrq1kFLjLWJQTbbBypi/ypnDypi/pdPa1srsOXOZ19rKrDlzWHuN1fIOqbBsg5Uxf1oWqjbsOSI2B34LTAd2Syk9scD9fRfz2BWBY8mGml9ZrRilrqSpqYn7Hvg7G2+8AVcM+hPjxj2ad0iSpDq2To/VOP7gPTnglPNZYblu7LzVpuyy9Ud49JkX+cvtD3DzfQ+z+cZ9Of24Q1l15ZXyDlfSMtaIc36rWfn9Clnn+vwFO74AKaXJi3nsUcDqwG0ppZeqE57UtbS1tfHxnQ+m36a7sP32W9Fv803zDkmSVMemz3yPkeOeYPhl3+cfA89l1uw53HL/wxy13y7ccun3GPqLb7H2Gqty4eC/5x2qJHVINTu/O5Uul2al5pNKl5d3ZOeIOCkixkXEuLbWd5fi5aSu4513ZjDq/jHsu9/ueYciSapjox+fRJ+ePeix6sp0a2lmnx234tGnX2TN1VehuamJpqYmPrX3Tkx41jqF1Iic89s5q5cup3TmQaXh0rsAk4HhHXlMSmlQSql/Sql/U3P3TgUpdQVrrtWD1VZbBYAVVliePffalUlPP59zVJKketZrrdV5bNK/mTV7DiklxkyYxEZ9evL6tOkf7HP32MfZZL1eOUYpSR1Xzc7v26XLPp18XEMtdDXf4Gsu4757h7Hpph/i+efGcsIJn8k7pEIxf5Xp1asnt9x2LQ+OGc4999/EyLtHMWLE3XmHVSi2wcqYv8qZw8qYv87b6sMbsN/HtuIzZ13MEadfSFtKHLnvzvzqz7dwxOkXcOQZFzL2iWc54/jD8g61EGyDlTF/tddWw61WolorvkbEb4CvAt9KKf2qg49ZAXgZWA3YcGnm+y63fF+XsFVuVmhZLu8QCu/9eXPyDkGScjN9zMC8Qyi0VT92ct4hqIubM3ty5B3DsnL8hkfUrF919Ys31CRv1az8/g6YB5xTGspcZhGrPX8aWAMY7kJXkiRJkpSPtpRqttVK1U51lFKaGBGnAAOBRyJiGDAJWBPoD8wA9lrgYfMXuhpUrbgkSZIkSV1P1Tq/ACmlKyJiAnA6sCcwAHgDeIwFzt8bEf2Aj9OJha4kSZIkSeqIqnZ+AVJKDwFHdGC/J4GGGSMvSZIkSUXViAspVXPOryRJkiRJdaHqlV9JkiRJUrG0NWDt18qvJEmSJKnhWfmVJEmSJJVJVn4lSZIkSSoeK7+SJEmSpDJteQdQBVZ+JUmSJEl1KyLWi4iREfFkRDwREd8o3d4jIv4REZNKl2ss7nns/EqSJEmSyrSRarZ1wDzg2ymlfsBOwKkRsTlwFnBXSunDwF2l64tk51eSJEmSVLdSSlNTSv8q/T0DeBLoAxwGXF3a7WpgwOKexzm/kiRJkqQytVztOSJOAk5qd9OglNKgRey7IbAtMAZYJ6U0FbIOckT0XNzr2PmVJEmSJOWm1NFdaGe3vYhYGbgBOC2lND0iOvU6dn4lSZIkSWXqbbXniOhG1vH9c0rpb6WbX42IdUtV33WB1xb3HM75lSRJkiTVrchKvL8HnkwpXdzurr8Dx5f+Ph4YtrjnsfIrSZIkSSqTUu3m/HbArsBxwOMRMb502/eAnwNDI+KLwH+ATy/uSez8SpIkSZLqVkppFLCoCb77dPR5HPYsSZIkSWp4Vn4lSZIkSWXaaniqo1qx8itJkiRJangNV/ldoWW5vEMotPfnzck7hEIzf5Vrq6/FFdTFNHXyfIH6Xx7DlVn1YyfnHUKhTR8zMO8QCq/3bt/MOwTViXo71dGyYOVXkiRJktTwGq7yK0mSJEmqTHLOryRJkiRJxWPlV5IkSZJUxtWeJUmSJEkqICu/kiRJkqQyqQFX77fyK0mSJElqeFZ+JUmSJEllPM+vJEmSJEkFZOVXkiRJklTG8/xKkiRJklRAVn4lSZIkSWU8z68kSZIkSQVk51eSJEmS1PAc9ixJkiRJKpOSw54lSZIkSSocK7+SJEmSpDIueCVJkiRJUgFZ+ZUkSZIklUlWfiVJkiRJKh4rv5IkSZKkMm2u9lwdEfGLiLgrIl6KiFkR8VZEPBIR50bEmnnHJ0mSJEkqtrro/ALfBLoD/wB+DfwZmAf8EHgsItbLL7RlY/nll2PkvTfywOhbGTN2BN/7/ml5h1Qogy6/kMkvjeeRf92ZdyiFZQ4rd8D+e/LEhPt4auIozjzj1LzDKRzzVxmP4crZBitjG+y8wbfey+Hf/iWf+vYFfOfXg5k9Zy6/u/529j35Rxx15kUcdeZF3P/Ik3mHWShNTU3cM2oYQ64flHcoDS/VcKuVeun8rppS2iml9IWU0lkppa+llHYAfgr0Br6bc3wVmz17DgcfeAy77nQQu+58MPvutzs77LBN3mEVxjWDr+fgQ47NO4xCM4eVaWpq4tJf/4SDDzmWLbfei6OPHkC/fh/OO6zCMH+V8xiujG2wcrbBznn1rXe49rZRDPnZN/nbRWfQ1pYY8eAjABx30O4M/eW3GfrLb7Pbtv1yjrRYTj7leJ55+rm8w1BBVb3zGxE7RsR1ETElImZHxNSIuCMijpq/T0rp/UU8fGjpsiE+nd599z0AunVroaVbC6kBx9FXy6hRY5g27e28wyg0c1iZHXfYlueee5EXXvgPc+fOZejQYRx6yAF5h1UY5q9yHsOVsQ1WzjbYea1trcyeM5d5ra3MmjOHtddYLe+QCq13717sd8CeDL566JJ3VsXaSDXbaqWqnd+IOBF4EBhQurwIuBXoCZzSgac4pHT5WDXiq7WmpiZGPXQLz704lpF3P8C4cY/mHZKkDurdpxcvTX75g+uTp0yld+9eOUZULOZPebMNqtbW6bEaxx+8Jweccj77fvlHrLLiCuyy9UcA+MvtD3DkGRfyg9/9hekz38s50uL46S++zw/P+SVtbW15h6KCqtpqzxGxOfBbYDqwW0rpiQXu77uQx5wOrAysBvQHPk7W8f15teKspba2Nj6+88Gsttoq/HnIQPptvilPTnwm77AkdUBE/M9tjt7oOPOnvNkGVWvTZ77HyHFPMPyy77PKSityxq+u5pb7H+ao/XbhpCP2I4D/GzqCCwf/nfO+8pm8w617+39iL15//U0eHf8Eu358x7zD6RJqWZGtlWpWfr9C1rk+f8GOL0BKafJCHnM6cC5wGlnHdwSwf0rp9cW9UEScFBHjImLcnHnTKw682t55Zwaj7h/DvvvtnncokjpoyuSprNe39wfX+/ZZl6lTX80xomIxf8qbbVC1NvrxSfTp2YMeq65Mt5Zm9tlxKx59+kXWXH0VmpuaaGpq4lN778SEZ1/KO9RC+NhO2/HJA/dh/ISRXHnVJey2+04MvOLCvMNSwVSz87tT6fK2jj4gpdQrpRRAL+BTwMbAIxGx3RIeNyil1D+l1H+5llWXOuBqWnOtHqy22ioArLDC8uy5165Mevr5nKOS1FFjx41nk002YsMN16Nbt24cddRh3HzLHXmHVRjmT3mzDarWeq21Oo9N+jezZs8hpcSYCZPYqE9PXp/230LN3WMfZ5P1HH7fEef/8CI+utlubPPRvfjSCadx/32jOfnE0/MOq6GllGq21UrVhj0Dq5cup3T2gSmlV4EbI+JfwDPANcBHl11otderV08GDrqA5uZmmpqCG28YzogRd+cdVmEMvuYydt99Z9ZaqwfPPzeW886/iKuu+kveYRWKOaxMa2sr3zjtbIbfei3NTU1cdfV1THTaQoeZv8p5DFfGNlg522DnbPXhDdjvY1vxmbMuprmpmc026sOR++7MDy8fytMvTiEi6L32Gpxz4qfzDlXqMqJaPe2IGEs2b7dfSumpCp7nEWAbYO2U0htL2n/V7hs33uD0Gnp/3py8Q1AX1+YcPOWoaSHzQtU5HsOVsQ1WZvqYgXmHUHi9d/tm3iEU2lszJjXMQbxT7z1r9oY++uV7apK3ag57Hl26/GSFzzN/gk5rhc8jSZIkSeoAT3XUOb8D5gHnlFZ+LjN/teeI2Cwi/meyQ0Q0RcRPyE6L9GBKaVoVY5UkSZIkNbCqzflNKU2MiFOAgWSLVg0DJgFrkg2HngHsBXwCuCAi7gOeA94E1gH2IFvw6hXgxGrFKUmSJEkqlxrwVEfVXPCKlNIVETGB7BRGewIDgDfIzt17ZWm3O4FBwK7A1mQLZb1LttDVYODSlNJb1YxTkiRJktTYqtr5BUgpPQQcsZj7JwCnVjsOSZIkSVLH1PIURLVSzTm/kiRJkiTVhapXfiVJkiRJxVLLVZhrxcqvJEmSJKnhWfmVJEmSJJVxzq8kSZIkSQVk5VeSJEmSVMY5v5IkSZIkFZCVX0mSJElSmWTlV5IkSZKk4rHyK0mSJEkq0+Zqz5IkSZIkFY+VX0mSJElSGef8SpIkSZJUQHZ+JUmSJEkNz2HPkiRJkqQyLnglSZIkSVIBWfmVJEmSJJVxwStJkiRJkgqo4Sq/78+bk3cIkirQFJF3CIXWiPNzasn8KW+2wcr03PXreYdQeG88MTTvEFQnGvH9yMqvJEmSJKnhNVzlV5IkSZJUGef8SpIkSZJUQFZ+JUmSJEllnPMrSZIkSVIBWfmVJEmSJJVxzq8kSZIkSQVk5VeSJEmSVCaltrxDWOas/EqSJEmSGp6VX0mSJElSmTbn/EqSJEmSVDx2fiVJkiRJDc9hz5IkSZKkMik57FmSJEmSpMKx8itJkiRJKuOCV5IkSZIkFZCVX0mSJElSGef8SpIkSZJUQFZ+JUmSJEll2qz8SpIkSZJUPHXZ+Y2I4yIilbYv5R2PJEmSJHUlqYb/1UrddX4jYj3gN8DMvGORJEmSJDWGuur8RkQAfwTeBAbmHM4yNejyC5n80nge+dedeYdSSOavcuawMuavcgfsvydPTLiPpyaO4swzTs07nMIxf5Uzh5Uxf0tv+eWXY+S9N/LA6FsZM3YE3/v+aXmHVBjX/O02Bpx4Joef9B3O/NllzJ4zh6ef+zfHnHYuh3/5O3z1Bxcy89338g6zIaWUarbVStU7vxGxY0RcFxFTImJ2REyNiDsi4qiF7P51YG/g88C71Y6tlq4ZfD0HH3Js3mEUlvmrnDmsjPmrTFNTE5f++iccfMixbLn1Xhx99AD69ftw3mEVhvmrnDmsjPmrzOzZczj4wGPYdaeD2HXng9l3v93ZYYdt8g6r7r36xltce9Pt/OWyH3PjoF/Q2trGbfc8xLmXXMlpX/gMN17+C/bZtT9//OuteYeqgqhq5zciTgQeBAaULi8CbgV6AqcssG8/4OfAr1NK91UzrjyMGjWGadPezjuMwjJ/lTOHlTF/ldlxh2157rkXeeGF/zB37lyGDh3GoYcckHdYhWH+KmcOK2P+KvduqTrZrVsLLd1aGvIcqtUwr7WV2bPnMK+1lfdnz6bnmmvw4uSX6b/lZgDsvO2W3DnqnzlH2ZjaSDXbaqVqnd+I2Bz4LTAd2C6l9OmU0vdSSl9KKW0DHNtu3xZgMPAf4HvVikmSlI/efXrx0uSXP7g+ecpUevfulWNExWL+KmcOK2P+KtfU1MSoh27huRfHMvLuBxg37tG8Q6p766zVgxOOPIj9jvs6e3/2VFbuvhK7bL8Vm2ywHiMfehiA2+8fwyuvv5VzpCqKalZ+v0J2HuHzU0pPLHhnSmlyu6s/ALYFTkgpzersC0XESRExLiLGtbU21GhpSWoI2ZIO5ax6dJz5q5w5rIz5q1xbWxsf3/lg+m26C9tvvxX9Nt8075Dq3jsz3mXkQw8z4upLuOvay5j1/mxuvmsU533rJP5y8z846tTv896sWXRrack71IbUiHN+q9lSdipd3ra4nSJiR7Jq70UppYeW5oVSSoOAQQDLLd/Xd2JJqjNTJk9lvb69P7jet8+6TJ36ao4RFYv5q5w5rIz5W3beeWcGo+4fw7777c6TE5/JO5y6NvqRCfTptTY9Vl8VgH133YFHJ07ikH0+zqCffReAFydP5b4x43OMUkVSzcrv6qXLKYvaod1w52eAc6oYiyQpR2PHjWeTTTZiww3Xo1u3bhx11GHcfMsdeYdVGOavcuawMuavMmuu1YPVVlsFgBVWWJ4999qVSU8/n3NU9W/dnmvy2JPPMuv92aSUGDP+CTZavzdvvv0OkFXTB117E0cdvE/Okaooqtn5fbt02Wcx+6wMbAr0A96PiDR/A84t7XNF6bZLqhZpDQy+5jLuu3cYm276IZ5/biwnnPCZvEMqFPNXOXNYGfNXmdbWVr5x2tkMv/VaJjx2D3/9681MtOLRYeavcuawMuavMr169eSW267lwTHDuef+mxh59yhGjLg777Dq3labbcJ+u+3IUad+n099+SzaUhuf/uTe3DbyIQ7+wrc59EtnsPaaazBg/z3yDrUhtaVUs61WolpjrCPiN8BXgW+llH61iH1WBH6ziKfYjmwe8CjgaeAfKaXrlvS6DnuW1JXV8gNEkurNSt2WzzuEwnvjiaF5h1Boy23Y/38nyBdUj1U+XLMvFW/NmFSTvFVzzu/vgJOBcyLi9pTSxPZ3RkTf0qJXX1rYgyPih2Sd36tTSldWMU5JkiRJUjuNuKhd1Tq/KaWJEXEKMBB4JCKGAZOANYH+wAxgr2q9viRJkiRJ81V1XfCU0hURMQE4HdgTGAC8ATwGWM2VJEmSpDrUhpXfTiudvuiIpXjcD4EfLut4JEmSJEldj2eEliRJkiSVacQ5v9U81ZEkSZIkSXXByq8kSZIkqUwjnj7Ryq8kSZIkqeFZ+ZUkSZIklUkNuNqzlV9JkiRJUsOz8itJkiRJKuOcX0mSJEmSCsjKryRJkiSpjOf5lSRJkiSpgOz8SpIkSZIansOeJUmSJEllPNWRJEmSJEkFZOVXkiRJklTGBa8kSZIkSSogO7+SJEmSpDIppZptSxIRn4iIpyPi2Yg4a2n/TXZ+JUmSJEl1KSKagf8DPglsDnw2IjZfmuey8ytJkiRJKpNquC3BjsCzKaXnU0pzgL8Ahy3Nv8nOryRJkiSpXvUBXmp3fXLptk5ruNWe58yeHHnHsDgRcVJKaVDecRSV+aucOayM+aucOayM+auM+aucOayM+auM+audeXOm1KxfFREnASe1u2lQu//PC4tjqZaitvJbeycteRcthvmrnDmsjPmrnDmsjPmrjPmrnDmsjPmrjPlrQCmlQSml/u229j9wTAbWa3e9L/Dy0ryOnV9JkiRJUr0aC3w4IjaKiOWAzwB/X5onarhhz5IkSZKkxpBSmhcRXwVuB5qBP6SUnlia57LzW3vOUaiM+aucOayM+aucOayM+auM+aucOayM+auM+euCUkrDgeGVPk905KTCkiRJkiQVmXN+JUmSJEkNz86vJEmSJKnh2fmVJEmSJDU8O7+SuqSIqNmJ2yVVh8dxZSLC74GSuhTf9JZC+w8LP3g7LyKa846hUZjLpZdc7W+p2e6Ut4hYGzyOl1ZE/BAgpdTm95jOa58z8ycVi53fpdNj/h8ppeQbX6d1a3/F/HVcRPSKiJ0i4mMAKaVWOyKdExHDIuLIvOMouLLT5NkGO8dqW2Ui4gfApRHxmbxjKaKIuB74QUR8E/wBYSmtGxEt8MH3QI/pToiIwyKiT95xqGvyYO2EiDgnIkYAkyLizoj4VUSskXdcRRERx0TERcDdEfHziDgA/AGhoyLip8A9wIPAQxHxN8g6wHnGVSQRcStwEO2+uKjjIuLEiLgcuCcifh0RJ4BtsKMioj9YbatERNwAfAvoCTyccziFExHDgSOAecDOOYdTOBHxtYi4EXiR7LvMWZAd07kGViARcQ9wI/D/IqJnzuGoC/I8vx0UEcOATwIvADOADwGrAY8BFwDDU0rT8ouwvkXEEOAooP0XvknA+SmlP+UTVXGUPmz3BiYAo4BPkbXBH6SUfhwR4a/3ixcRtwF7At8F/phSeiffiIql1Ok4hOz9bzZZ56MJGAGcBjxnJ3jRStW2rYBvpZRuLd3mcdsJEXEN2XvfT8mO4aml2z/IY0Q02w4Xrt174KVkx/JmwEEppdvyjKsoIuJa4FDgNeBl4KPA8sDJKaWr84ytKCJiB2AM2Y8vs4CfAX9IKb2Wa2DqUqz8dkCpWrk/8EPgY8AOwLbAdcAmwIXAiRGxVl4x1rOIGEr2gfFbYHNgL+BiYH3g6IhYKcfw6l5EXAbsAfwCOCyl9B2y9jgdKJv3ZjVp4Upf+vYCvg9ctbiOr8PX/ldEXEX2498FZMfwVmQ/xrwCfAIYDOwTEcvlFWM9i4j/I6u2bQycGxGfAEe9dEZEfJLsc2QQcPn8jm/JRhGxATgKYVHadXy/V/oMuaR011ERsZzve4sXEX8l+8HgN2TfA/cEvkD2g/42C+zrMb1ob5N1fIcCj5N9Jn/BCrBqyTe7JYiIlck6GmOBy1JKbwPdUkovAqcCPwbagDOA4yJi1ZxCrUsR8R2yTscvyKqUT6WU7gUGkr3xHUT2Q4IWIiK2JauY3wEMSim9AZBSeoGscr5KRKwbETtGxPJWkf5XqWq+F1l1cnBK6e2I6BYRq0fEaRHxi4j4YUQcDR8MSfW9sSQi9gWOBG4CLkkpvQpMSyndR/ZlcDrZD4IXk30pdA5wOxFxLNmX5IeBK4D+wI9LnTk7wB23I9CdrA2+GRErR8QBEfF34FHgsYi4OyI+FRE9Fv9UXUtpuseewPeAq0o3jwAmkv141cuh+IsWEeeTfYZcCFyQUno9pTSP7HvhLGCl0n5N4BzgRSmN0JhE9t1vCtkPMJNZSAfYzxBVkwfnkvUFtgCeTSlNj4jlUkpzSgfxW8BlwC+BVuCbwC7ggQsQEZsAnwOeB65IKU1r9+HwLHBzaddVcgqxCDYF1gKunt/xBYiIQ4GtgX7AvcBo4L6IOMhK+n9FxLnAYcDTwE0ppddLX4w/DdxF1mE7A/gBMCQi/gJ2gBewCdmXuz+W8tdcWmitG/Ak2RfoqWQV4QtLP8K0+kUaStXIL5L9QPrFlNIpZNXz7bAD3CGRaSEbYvoaMDUiVgE+C/wJ2JWsDb5J1sG7jGwk1uq5BFxnIuI6slEb3wV+32561hSyzts6wGml49ofTxcQER8HvgLcDQwsfe+bb09K318i4hbg/oj4Q0Ss5mfI/2rXvt4CNk8p/ZXss/dFsg7wlwBKoyjPjojeecSpxueBuWSvk33gfjQimtp1fFPpcibwB+Byso7y2aXbHXoFvcnmBV6YUppayktbux8GXmm3nxaub+nygPkfpBGxH3AW2fH7GPB34H6y6ttFZF+sHb6b+Q3wD2BLstVhVyMbQv5bYDngO8AxpcvXyYYA/glcwKRd+9m4dLlN6T2wNSJaUkpzU0rvka19MAq4lawN/gxcQbbkNbJ2dUZK6bFSB/cCsh9Mt2UhHWA7weVSZh7ZF+YeZMNMW4BzyX7U2hTYiezHwB+VHnYq/30f7LL5LP0A8ABwCtmPV9NLTayp9B3lJ8CrZAtfza9edtl8LcLjwEvAL0qjXgCIiN3IRhM1kX2HmUf2Q8IJwC0RsZLV9HLtvvs9CHyk9PdNZCMo/wOcFRE/A54B/h+wQa1jVBeRUnJbzEb2Bfl+sl/uvw20lG6PBS7XBu4r7felvOOuhw3oQ9ax6LXA7fNzdnApX8eVrjct5Dki739HzjnckKyqNhe4gWzI2itkCw4d2G6/NciGkrcBt+Uddz1s7Y7V1cmGjbcBI4F/k334rrjA/luWcjsHODjv+OtlAw4stbdbyb6wNM/PL3A82Ryug0tt9Q2yL9steced9zb//YxsQZxVF7hvTeDnpTb5MPDJJT1PV93afV58p5Svc4GzyTrD65Xu61a6XI1sMaw2YFjesdfDBqzYLj/R7vYofW7cWsrXV/KOtd629u91C1zfnmy01ftk05JWKt3eG7izlM9f5B1/vW6lz5Q2YMvS9eXJphc+TfYjwkyyuem5x+rWmJuVoYWY/0tdqVI5h+zDdjpwLLD3ApXfVPoV9XXgfLIDd6Pcgq8D7YY2TwFuSCm90v7+lNKCFaH3Sre3lR6/V0Scuoh9G177X4pTNrf882QdtgFkQ/xayeZPD2/3K/40si/TbwBbRBc/f17p2JxXys3bwNFkw5z3IKvGHZpSmlUaTjl/hdjHgavJOnXr5RR6XVigWjGRrEP7SbKOxbER0Rc4EziHLJ+PlNrqSLIqUld/D4z572cppdkppenzby/d9ib/WwE+qN3jvxgRl5T27ZIjENrlav5nwJ/Ifpz6FNnc8mnArFKu55Yu3yH7EfANYMPS8Oguqd3n8Kx2+fng8zRlppHlC2BARKxqpTLTfgRfykYeQNZhg2yIfQ+ylbKHppTeK+3/Mtm86vfJfvzv0hbWlkrt8lWy7zFrQfYeSdbxXQtIQDOQuvLxq+ryPJcLKH1Znv8G1zsiWlNKd0fEYLKhQ2cC70fE/fM7wO0e/hpZTtepcdh1o33+Sh2wNrI5Wgs7pcf8PC/f7vH7k30hXD0i/praDTPqChaSv3kppRERsT2wLvAOWSfumfkPaffw18mqlq+RfTHskhY4htctXX8psgWtrgDuSim9Mb+DXNpvftucUrpcrZYx15OFtMFXyYaR/oFs/vThZF9cmsnm/B5Y+qELskXYoLxddikLyV/r/B8AF+h8vBkRF5Sungn8MCLmkX2pPg9YLSIuaJfbLmMhOYyU0uSIuJhsaPP8URptpc/hZrJjOJG9D84mOyXX+7n8A3K2uDa4ECPJPlP2ArZIKT1UozDr1sK+x6SUprYrerwYEduUOr3z920ie198j2zEYJd9D4RFt8GUDQWfQDai7WBgZERsTLZ2CWQ/QO8EnA6sFBGXlopL0jJj57edBQ7WLwLHAU0RcRjwO7LOx6fI8variBieUprLf78470T2oTuu9Bxd6hyOC8nfsUBzRHy2/Re4dnmZP/9jTun2T5BVljYGPt7FO77t29+xKaX/AO9ExNbAhynNhVmgKnQ00Av4K9kw6S5nMW3wc6UvLMeRrRj7QUekfZWObEXZ98imOngMZwvWBdmKsCcCu5Gt8Pwq8ATZQmztv5h8lGyUwr9rGXe96Oh74HylDvDFZCOGvke2WFOv0vWd7PiW5fAIsqkfH+K/73WXRsQXS5Wj+Y4kW2viL2SdkS5lKdrgzIi4F9gH+GZEPJ6ytUy6pCXlr93nwSz4YHHE9uu8HEN2/A4vPUeX+gyBDrXBRPYj/coR0Z1syuCKZFMbriIbFv07svnTl9Q6fnUBqQ7GXtfDRvlcmHOBd8lOxH1Mu9u3JvtAnQM8R7a4UG+yX+qPJlt86FlK85C60raY/P2/xTzmSLLq7yHAx4FHyIaXb5n3v6de80c2r3I68E9g/wVyOYFs0YiN8v731GMO29/fbr+mdn8fQdapGwGskfe/p47yd2wHH38EWTXu90C3heW7kbelfA+cP591DbKF69rIhlRukfe/p85y2P5zeHOyHwneLOVrCNmK5H3IfqB5gmwEx8Z5/3vqKH8LbYPt2t8qZKeLmgRskPe/oyj5K+3X/jPkMP67psQ6ef976jGH7drcxWQj2V4hWzfiZP47t3o5shFGXe4YdqvNlnsA9bYBXyb71W4g8NHSbe0P5k1LB/SrpQ/eqaVtBtn5yj6a97+h3vK3mH0/Xcrhr8kWj5gObJX3v6Ge80e2IudvySq7/wFuA24v5e61rt7+OpLDRTzmGLJVPV8HPpL3v6Fe80c2tG/+l5eWdrf/P2A88DKwSd7/hnrN32Iec0LpS+BbQL+8/w15bx14H9yAbCj+S6XPkGmlL9KzyE6t16XfBzv5ORxkU48uLeXyJ3nHn/e2lMfw8aXPkDc9hjt0DB9Tam8vkHV853+udMs7drfG3+Y3NgERsQ6loSpk1Y4nS7eXDVuJ7PyWG5Od13d9sl+pxgBXppReqG3U9aMT+Zu/UNhngT+TvUG+TzbU+bFax10vOpG/rcm++B1KNrzvFbLzNZ6RUnqGLqyjOSzd1kRWcbuAbL5bkK3yPKGGIdeVzuSvdPsKZD/GHED2g4z560T+SvcdSjbPrQnYJaX0RE2CrVOdPIb7kK3FsQGwAtnn8HUpmybSJS1NGyzd/3FgKHBAyhb/65KW4jOkJ1kVc1ey98ABXfk9EDr1XeZYsvz9qvSdsP16HVLVOOe3XG+ylTfPTik9Of9AXfANL2XzfJ+OiK8s7sOkC+po/uZfn1G6nEs2v21iDWOtRx3N36MRcQbZB+62ZMPFX0nZqsZdXYdyWNKd7IvzEWSrGX8jpTRpIft1JZ3JH2TDm1ckO13KL1JKz9Uq0DrVqfyVFmrqTjZl4dSu3vEt6VAOS1+Up0TE2X4Ol+lsGwyyqtuoiOiXshWzu7LO5G9FslEve5Mt2PQ93wOBJeSw3fU/zX9AZGdc6HJz9JUPO7/l5q/SvBL872l25h+cEdETWLv9F5WuuKjBQnQmf6uTdTh+CfwhdfGKZUlH87cOsFap/T1V4xjrXWdyuALZkPv7gcdSSm/VNNL61JljuGdKaUJEHE82BPq9GsdajzqTv7VSShMj4m9k5+Z+u7ah1q0O5RBYKyLWav+jqZ/DQOfa4Jopq8ql0r5dveMLnfsMWYls/vk/gH+n0inNtPgcUloZu/37oB1f1ZKd33LzV0LcKiJWbf9GtsBqfj8D1oyI41JKM6Brno92ITqav5+TLRJ2BHBOyirp6nj+fkrW/o5NXXhVzkXozDHcA/hsSumeGsdYzzr7Hnh86QvznFoHWqeWNn+zF3yiLszP4cosdf4EdP4z5JjUhYeJL4JtUHWtKe8A6swk4A6yc48d0/6OdsM1jgb2J5uk7xe+ch3N335kKyK22PEt09n2Z+7+V2fa4Iv891zTynS2DXbJ86guhvmrnJ/DlTF/lensZ8g8tCDboOpbqoNVt+ppA7Yg+0LSBnwL6NvuviPJ5lc+Sxc9nYz5M3/1vplD82f+ir2ZQ/Nn/oq9mUO3et5c7XkhImI74B5gZbKl658G1gS2Ixuetm/q4qv5LY75q4z5q5w5rIz5q4z5q5w5rIz5q4z5q5w5VL2y87sIEfER4DtkJ9ruTnZO1fuAn6aUns0ztiIwf5Uxf5Uzh5Uxf5Uxf5Uzh5Uxf5Uxf5Uzh6pHdn6XICLWBVYlO5fqrJSScxM6wfxVxvxVzhxWxvxVxvxVzhxWxvxVxvxVzhyqntj5lSRJkiQ1PFd7liRJkiQ1PDu/kiRJkqSGZ+dXkiRJktTw7PxKkiRJkhqenV9JkiRJUsOz8ytJkiRJanh2fiVJkiRJDc/OryQpVxHRGhHjI2JCRFwfEStV8FxXRcSRpb+vjIjNF7PvnhGxy1K8xosRsVZHb19gn5mdfK0fRsTpnY1RkiT9Lzu/kqS8zUopbZNS+igwBzi5/Z0R0bw0T5pS+lJKaeJidtkT6HTnV5IkFZOdX0lSPbkf2KRUlR0ZEdcCj0dEc0RcEBFjI+KxiPgyQGQui4iJEXEr0HP+E0XEPRHRv/T3JyLiXxHxaETcFREbknWyv1mqOu8WEWtHxA2l1xgbEbuWHrtmRNwREY9ExOVALOkfERE3RcTDEfFERJy0wH0XlWK5KyLWLt32oYgYUXrM/RGx2TLJpiRJ+kBL3gFIkgQQES3AJ4ERpZt2BD6aUnqh1IF8J6W0Q0QsDzwQEXcA2wIfAbYE1gEmAn9Y4HnXBq4Adi89V4+U0lsRMRCYmVK6sLTftcCvUkqjImJ94HagH3AuMCqldF5EHASUdWYX4Qul11gRGBsRN6SU3gS6A/9KKX07In5Qeu6vAoOAk1NKkyLiY8Bvgb2XIo2SJGkR7PxKkvK2YkSML/19P/B7suHI/0wpvVC6fX9gq/nzeYHVgA8DuwNDUkqtwMsRcfdCnn8n4L75z5VSemsRcewLbB7xQWF31YhYpfQanyo99taImNaBf9PXI+Lw0t/rlWJ9E2gDrivd/ifgbxGxcunfe327116+A68hSZI6wc6vJClvs1JK27S/odQJfLf9TcDXUkq3L7DfgUBawvNHB/aBbCrQzimlWQuJpSOPn7//nmQd6Z1TSu9FxD3ACovYPZVe9+0FcyBJkpYt5/xKkorgduArEdENICI2jYjuwH3AZ0pzgtcF9lrIYx8C9oiIjUqP7VG6fQawSrv97iAbgkxpv21Kf94HHFO67ZPAGkuIdTVgWqnjuxlZ5Xm+JmB+9fr/kQ2nng68EBGfLr1GRMTWS3gNSZLUSXZ+JUlFcCXZfN5/RcQE4HKy0Us3ApOAx4HfAfcu+MCU0utk83T/FhGP8t9hxzcDh89f8Ar4OtC/tKDWRP676vSPgN0j4l9kw6//s4RYRwAtEfEYcD4wut197wJbRMTDZHN6zyvdfgzwxVJ8TwCHdSAnkiSpEyKlDo/kkiRJkiSpkKz8SpIkSZIanp1fSZIkSVLDs/MrSZIkSWp4dn4lSZIkSQ3Pzq8kSZIkqeHZ+ZUkSZIkNTw7v5IkSZKkhmfnV5IkSZLU8P4/6Y842trErQgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1296x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_heatmap(ytest,ypred,class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37d4e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred_class = np.argmax(ypred,axis=1)\n",
    "# print(ypred_class[:10])\n",
    "ytest = np.argmax(ytest,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "858a9691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.860201\n",
      "Precision: 0.860223\n",
      "Recall: 0.860201\n",
      "F1 score: 0.860021\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(ytest,ypred_class)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(ytest, ypred_class,average='weighted')\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(ytest,ypred_class,average='weighted')\n",
    "print('Recall: %f' % recall)\n",
    "# f1: 2 tp / (2 tp + fp + fn)\n",
    "f1 = f1_score(ytest,ypred_class,average='weighted')\n",
    "print('F1 score: %f' % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688c182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
